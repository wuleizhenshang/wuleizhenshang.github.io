<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>自然语言处理（选修课） | Blog-无泪真伤</title><meta name="author" content="无泪真伤"><meta name="copyright" content="无泪真伤"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="自然语言处理（选修课）写在前面 个人代码水平并不高，文中代码也是按照老师讲解和个人思路纯手打和debug出来的，许多代码也只是解决了test测试中的问题，需要更高深的代码可以绕道了，文章仅用于记录个人学习经历。 理论部分简介NLP分析技术大致分为三个层面：词法分析、句法分析和语义分析。  词法分析 词法分析是为了分析文本中的词汇和标记，主要任务包括分词、词性标注、命名实体识别。  分词：将文本分割">
<meta property="og:type" content="article">
<meta property="og:title" content="自然语言处理（选修课）">
<meta property="og:url" content="https://www.wuleizhenshang.love/2023/11/18/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E9%80%89%E4%BF%AE%E8%AF%BE%EF%BC%89/index.html">
<meta property="og:site_name" content="Blog-无泪真伤">
<meta property="og:description" content="自然语言处理（选修课）写在前面 个人代码水平并不高，文中代码也是按照老师讲解和个人思路纯手打和debug出来的，许多代码也只是解决了test测试中的问题，需要更高深的代码可以绕道了，文章仅用于记录个人学习经历。 理论部分简介NLP分析技术大致分为三个层面：词法分析、句法分析和语义分析。  词法分析 词法分析是为了分析文本中的词汇和标记，主要任务包括分词、词性标注、命名实体识别。  分词：将文本分割">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.imgdb.cn/item/65586ff1c458853aef149c7e.jpg">
<meta property="article:published_time" content="2023-11-18T15:29:30.000Z">
<meta property="article:modified_time" content="2024-04-02T05:02:52.676Z">
<meta property="article:author" content="无泪真伤">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="自然语言处理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/65586ff1c458853aef149c7e.jpg"><link rel="shortcut icon" href="/img/86634.jpg"><link rel="canonical" href="https://www.wuleizhenshang.love/2023/11/18/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E9%80%89%E4%BF%AE%E8%AF%BE%EF%BC%89/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 无泪真伤","link":"链接: ","source":"来源: Blog-无泪真伤","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '自然语言处理（选修课）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-02 13:02:52'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/65582252c458853aeff7c6f5.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.imgdb.cn/item/65586ff1c458853aef149c7e.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Blog-无泪真伤"><span class="site-name">Blog-无泪真伤</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">自然语言处理（选修课）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-18T15:29:30.000Z" title="发表于 2023-11-18 23:29:30">2023-11-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-02T05:02:52.676Z" title="更新于 2024-04-02 13:02:52">2024-04-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">19.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>70分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="自然语言处理（选修课）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="自然语言处理（选修课）"><a href="#自然语言处理（选修课）" class="headerlink" title="自然语言处理（选修课）"></a>自然语言处理（选修课）</h1><p><strong>写在前面</strong></p>
<p>个人代码水平并不高，文中代码也是按照老师讲解和个人思路纯手打和debug出来的，许多代码也只是解决了test测试中的问题，需要更高深的代码可以绕道了，文章仅用于记录个人学习经历。</p>
<h2 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>NLP</strong>分析技术大致分为三个层面：<strong>词法分析、句法分析和语义分析</strong>。</p>
<ol>
<li><p>词法分析</p>
<p>词法分析是为了分析文本中的词汇和标记，主要任务包括分词、词性标注、命名实体识别。</p>
<ul>
<li>分词：将文本分割成单词、标记或短语的过程。<strong>分词是NLP任务的基础</strong>。</li>
<li>词性标注：词性标注是为文本中的每个单词或标记分配一个词性（名词、动词、形容词等）的过程。</li>
<li>命名实体识别：命名实体识别是用于识别文本中的命名实体，如人名、地名、组织名、日期等的任务。</li>
</ul>
</li>
<li><p>句法分析</p>
<p>句法分析涉及理解句子的结构和语法关系，以便对文本进行更深入的分析和理解。两种<strong>主流</strong>的句法分析方法为<strong>短语结构句法体系、依存结构句法体系（后者为当前热点）</strong>。</p>
<ul>
<li>依存句法分析：依存句法分析研究词汇之间的依存关系，即一个词与句子中其他词之间的语法依赖关系。这些依赖关系通常表示为有向图中的弧，其中一个词是另一个词的依赖项。依存句法分析有助于理解词与词之间的语法关系，如主谓关系、修饰关系等。</li>
<li>短语结构句法分析：短语结构句法分析关注句子中短语的结构，包括短语的组成和嵌套关系。这种分析将句子分解为短语和子句，以揭示句子的语法结构。</li>
</ul>
</li>
<li><p>语义分析</p>
<p>语义分析涉及理解文本的语义含义和关系，以便深入理解文本内容。</p>
<ul>
<li>词义消歧</li>
<li>命名实体链接</li>
<li>情感分析</li>
<li>语义角色标注</li>
<li>语义关系抽取</li>
<li>问答系统</li>
<li>自然语言生成</li>
<li>语义相似度计算</li>
<li>知识图谱</li>
</ul>
</li>
</ol>
<h3 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h3><h4 id="概率论基础"><a href="#概率论基础" class="headerlink" title="概率论基础"></a>概率论基础</h4><ul>
<li><strong>样本空间(Sample Space)</strong></li>
</ul>
<p>通常把随机试验的每一个可能结果称为一个<strong>样本点</strong>，样本点的全体称为<strong>样本空间</strong>用Ω表示</p>
<p>样本空间的子集称为<strong>事件</strong>,常用A,B,…表示</p>
<p><strong>概率函数</strong>是从随机试验中的事件到实数域[0,1]的映射函数，用以表示事件发生的可能性，通常：P(A) 表示事件A的概率函数，概率函数具有以下公理性质：</p>
<p>0≤ P(A) ≤1，对每个属于 Ω 的事件A</p>
<p>P(Ω)&#x3D;1</p>
<p>A∩B&#x3D; , P(A ∪ B)&#x3D;P(A)+P(B)</p>
<ul>
<li><strong>条件概率和独立性(Conditional Probability independence)</strong></li>
</ul>
<p>两个事件A,B同时发生的概率为事件A,B的交集的概率，P(A∩B)<br>两个事件A，B<strong>独立</strong>，则满足：P(A∩B)&#x3D;P(A)·P(B)</p>
<p>P(A|B) 在已知事件B发生的基础上，判断事件A发生的概率，这个叫<strong>条件概率</strong></p>
<p>𝑃(𝐴 ∩ 𝐵) &#x3D; 𝑃(𝐵)𝑃(𝐴|𝐵) &#x3D; 𝑃(𝐴)𝑃(𝐵|𝐴)</p>
<p>若事件A1，A2，…,An<strong>互相独立</strong>，则：<br> 𝑃(𝐴1 ∩ ⋯ ∩ 𝐴𝑛)&#x3D; 𝑃(𝐴1)𝑃(𝐴2) ⋯ 𝑃(𝐴𝑛)</p>
<ul>
<li><strong>贝叶斯定理 (Bayesan theorem)</strong></li>
</ul>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310102149798.png" alt="image-20231010214956681"></p>
<p>贝叶斯定理实际是概率转换公式，求P(A|B)可以转换为计算P(B|A)</p>
<h4 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h4><ul>
<li><strong>熵 (entropy)</strong></li>
</ul>
<p>熵表示单个随机变量的不确定性的均值，随机变量的熵越大，它的不确定性越大，即能正确估计其值得概率越小</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310102152759.png" alt="image-20231010215210715"></p>
<p><strong>熵的一些属性</strong></p>
<p>H(X)&gt;&#x3D;0</p>
<p>H(X)&#x3D;0, 当且仅当随机变量X的值是确定的，没有任何信息量可言</p>
<p>熵值随着信息长度的增加而增加</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310102157205.png" alt="image-20231010215707135"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310102157758.png" alt="image-20231010215727688"></p>
<ul>
<li><strong>联合熵和条件熵(Joint entropy and conditional entropy)</strong></li>
</ul>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310102159546.png" alt="image-20231010215949489"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310102200379.png" alt="image-20231010220043319"></p>
<p>熵是对不确定性的度量，我们知道的越多，熵越小。<br>如果一个语言模型可以捕获的语言结构信息越多，那么，熵越小。<br>因此，我们可以使用熵作为对语言模型的一个度量。</p>
<ul>
<li><strong>互信息 (mutual information)</strong></li>
</ul>
<h3 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h3><hr>
<h3 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h3><h4 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h4><p><strong>主要任务</strong></p>
<ol>
<li><strong>分词（Tokenization）</strong>：将文本拆分成单词或标记。单词是语言中的最小单位，可以是单个词汇或符号。分词是文本处理的基础，它将连续的字符序列切分成离散的单词。</li>
<li><strong>去除停用词（Stop Word Removal）</strong>：停用词是在文本中频繁出现但通常不携带重要信息的词汇，例如“的”、“是”、“在”等。在词法分析中，通常需要去除这些停用词，以减少文本的噪音和提高处理效率。</li>
<li><strong>词干提取（Stemming）</strong>：词干提取是将词语转换为它们的基本形式或词干的过程。例如，将单词的不同时态或复数形式转换为其原始形式，如将“running”转换为“run”。</li>
<li><strong>词性标注（Part-of-Speech Tagging）</strong>：词性标注是为文本中的每个词语分配其词性或语法角色的任务。词性标记可以帮助理解句子的结构和含义。</li>
<li><strong>命名实体识别（Named Entity Recognition）</strong>：命名实体识别是识别文本中特定类型的实体，如人名、地名、组织名等。它有助于从文本中提取重要信息。</li>
<li><strong>拼写检查（Spell Checking）</strong>：拼写检查是检测文本中的拼写错误并提供纠正建议的过程。它可以帮助提高文本质量和可读性。</li>
<li><strong>标点符号处理</strong>：在词法分析中，通常需要处理文本中的标点符号，包括分句和分段。</li>
<li><strong>数字处理</strong>：处理文本中的数字，包括数字的规范化、转换和提取。</li>
</ol>
<p><strong>（这里主要讲了中文相关的分词、词性标注）</strong></p>
<p><strong>语言的分类</strong></p>
<p>传统语言学根据词的形态结构通常把语言分为三大类：</p>
<ul>
<li><p>分析型语言（ 如：汉语、藏语）</p>
<ul>
<li>词没有专门表示语法意义的附加成分</li>
<li>形态变化少</li>
<li>语法关系靠词序、虚词来表示</li>
</ul>
</li>
<li><p>黏着性语言（如：日语、朝鲜语）</p>
<ul>
<li>词前中后有专门表示语法意义的附加成分，一个附加成分表达一种或多种语法意义</li>
<li>词根或词干跟附加成分的结合不紧密</li>
</ul>
</li>
<li><p>屈折型语言（如：英语、德语、法语、西班牙语等）</p>
<ul>
<li>用词的形态变化来表示语法关系，一个形态成分可以表示若干种不同的语法意义</li>
<li>词根或词干跟词的附加成分结合得很紧密，往往不容易截然分开</li>
</ul>
</li>
</ul>
<p><strong>不同的语种本身的结构差异很大，语种之间的语料资源也差异很大，所以，面对不同的语种在自然语言处理方法上会有所差异</strong></p>
<h4 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h4><h5 id="相关知识-1"><a href="#相关知识-1" class="headerlink" title="相关知识"></a>相关知识</h5><p><strong>分词的必要性</strong></p>
<p>分词可以初步帮助我们理解文本的语义信息</p>
<p><strong>分词算法评测标准</strong></p>
<p>通常的评测指标包括：</p>
<ul>
<li><p>正确率P</p>
<p>正确率通常指测试结果中正确切分的个数占系统所有输出结果的比例</p>
</li>
<li><p>召回率R</p>
<p>召回率是指测试结果中正确结果的个数占标准答案总数的比例</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202309201933240.png"></p>
</li>
<li><p>F度量值</p>
<p>正确率和召回率的综合值</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202309201935821.png"></p>
</li>
</ul>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311011833235.png" alt="image-20231101183347111"></p>
<p><strong>汉语自动分词主要方法</strong></p>
<ul>
<li>基于规则的中文分词方法</li>
<li>基于统计的中文分词方法</li>
<li>基于神经网络的中文分词方法</li>
</ul>
<h5 id="基于规则的中文分词方法"><a href="#基于规则的中文分词方法" class="headerlink" title="基于规则的中文分词方法"></a>基于规则的中文分词方法</h5><p><strong>基本思路和特点</strong></p>
<p>事先人工建立好分词词典；<br>基于字符串匹配进行分词，通常需要足够大的词表；<br>经典算法包括：正向最大匹配法、逆向最大匹配法、双向匹配法等。<br>优缺点：受限于分词词典的覆盖面。</p>
<p><strong>优缺点</strong></p>
<p>优点：容易实现</p>
<p>缺点：①参数MaxLen不好取：太大，匹配所花时间多，算法时间复杂度提高，太短，不能切分长度超过它的词，导致切分正确率降低。②很多歧义无法处理，例如：幼儿园&#x2F;地&#x2F;节目&#x2F;  以及  幼儿&#x2F;园地&#x2F;节目&#x2F;	③最重要一点，准确率不高。</p>
<h6 id="正向最大匹配法"><a href="#正向最大匹配法" class="headerlink" title="正向最大匹配法"></a>正向最大匹配法</h6><p><strong>算法描述</strong></p>
<p>输入：分词词典、待切分语料<br>参数：最大词长maxLen，读取字符串长度len，读取字符串的指针起始位置pos<br>伪代码：<br>（1）初始化定义一个maxLen，令len&#x3D;maxLen，pos&#x3D;0；<br>（2）从待切分语料中从字符串下标0的位置开始正向向后取maxLen的字符串str(取不够则全部取完)；<br>（3）将str与词典进行匹配：<br>①若匹配成功，则认为字符串str为词，pos向后移动len长度，返回步骤（1）<br>②若匹配失败：如果len&gt;1，则len减1，从待切分语料中从pos往后取长度为len的字符串str，返回步骤（3）；否则，得到长度为1的单字词，pos向后移动1长度，返回步骤（1）</p>
<p><strong>代码（个人书写）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 递归写法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recursionMatch</span>(<span class="params">maxLen, dic, target</span>):</span><br><span class="line">    result = []</span><br><span class="line">    recursionMatchSolve(maxLen, dic, target, <span class="number">0</span>, maxLen, result)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># maxLen表示每次取词最大长度，dic是字典，str是待切分语料，start是当前开始切分位置，tempLen是当前切分长度，result保存结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recursionMatchSolve</span>(<span class="params">maxLen, dic, target, start, tempLen, result</span>):</span><br><span class="line">    <span class="comment"># 先添加终止条件</span></span><br><span class="line">    <span class="comment"># start&gt;=len(str)表示已经匹配完成了，返回</span></span><br><span class="line">    <span class="keyword">if</span> start &gt;= <span class="built_in">len</span>(target):</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 先把当前需要比较字符获取出来</span></span><br><span class="line">    <span class="keyword">if</span> start + tempLen &lt;= <span class="built_in">len</span>(target):</span><br><span class="line">        temp = target[start:start + tempLen]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        temp = target[start:<span class="built_in">len</span>(target)]</span><br><span class="line">    <span class="comment"># len=1表示当前取的字段只剩一个字，不管是否匹配成功都加入结果</span></span><br><span class="line">    <span class="keyword">if</span> tempLen == <span class="number">1</span>:</span><br><span class="line">        result.append(temp)</span><br><span class="line">        recursionMatchSolve(maxLen, dic, target, start + <span class="number">1</span>, maxLen, result)</span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 记得return</span></span><br><span class="line">    <span class="comment"># 比较词典中的词</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> dic:</span><br><span class="line">        <span class="keyword">if</span> i == temp:</span><br><span class="line">            result.append(i)</span><br><span class="line">            recursionMatchSolve(maxLen, dic, target, start + tempLen, maxLen, result)  <span class="comment"># 匹配成功就重置len</span></span><br><span class="line">            <span class="keyword">return</span>  <span class="comment"># 记得return</span></span><br><span class="line">    recursionMatchSolve(maxLen, dic, target, start, tempLen - <span class="number">1</span>, result)  <span class="comment"># 匹配失败</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 迭代写法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">iterationMatch</span>(<span class="params">maxLen, dic, target</span>):</span><br><span class="line">    result = []</span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 循环中写终止条件</span></span><br><span class="line">    <span class="keyword">while</span> start &lt; <span class="built_in">len</span>(target):</span><br><span class="line">        tempLen = maxLen</span><br><span class="line">        found = <span class="literal">False</span>  <span class="comment"># 记录本次是否匹配成功，匹配成功则退出下面循环，不然就会一直找到tempLen=0，中途找到结果会出问题</span></span><br><span class="line">        <span class="keyword">while</span> tempLen &gt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> start + tempLen &lt;= <span class="built_in">len</span>(target):</span><br><span class="line">                temp = target[start:start + tempLen]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp = target[start:<span class="built_in">len</span>(target)]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">            <span class="keyword">if</span> tempLen == <span class="number">1</span>:</span><br><span class="line">                result.append(temp)</span><br><span class="line">                start = start + <span class="number">1</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> dic:</span><br><span class="line">                <span class="comment"># 匹配成功就跳出本次循环</span></span><br><span class="line">                <span class="keyword">if</span> i == temp:</span><br><span class="line">                    result.append(temp)</span><br><span class="line">                    start = start + tempLen</span><br><span class="line">                    found = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 找到结果退出循环</span></span><br><span class="line">            <span class="keyword">if</span> found:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 暂时找不到</span></span><br><span class="line">            tempLen = tempLen - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>





<h6 id="反向最大匹配法"><a href="#反向最大匹配法" class="headerlink" title="反向最大匹配法"></a>反向最大匹配法</h6><p><strong>算法描述</strong></p>
<p>输入：分词词典、待切分语料<br>参数：最大词长maxLen，读取字符串长度len，读取字符串的指针起始位置pos<br>伪代码：<br>（4）初始化定义一个maxLen，令len&#x3D;maxLen，pos&#x3D;待切分长度-1；<br>（5）从待切分语料中从字符串最后一个下标的位置开始反向向前取maxLen的字符串str(取不够则全部取完)；<br>（6）将str与词典进行匹配：<br>①若匹配成功，则认为字符串str为词，pos向前移动len长度，返回步骤（1）<br>②若匹配失败：如果len&gt;1，则len减1，从待切分语料中从pos往前取长度为len的字符串str，返回步骤（3）；否则，得到长度为1的单字词，pos向前移动1长度，返回步骤（1）</p>
<p><strong>代码（个人书写）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 递归写法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recursionMatch</span>(<span class="params">maxLen, dic, target</span>):</span><br><span class="line">    result = []</span><br><span class="line">    recursionMatchSolve(maxLen, dic, target, <span class="built_in">len</span>(target) - <span class="number">1</span>, maxLen, result)</span><br><span class="line">    <span class="comment"># 翻转list</span></span><br><span class="line">    result.reverse()</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># maxLen表示每次取词最大长度，dic是字典，str是待切分语料，end是当前最后的切分位置（下标），tempLen是当前切分长度，result保存结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recursionMatchSolve</span>(<span class="params">maxLen, dic, target, end, tempLen, result</span>):</span><br><span class="line">    <span class="comment"># 先添加终止条件</span></span><br><span class="line">    <span class="comment"># end &lt; 0表示已经匹配完成了，返回</span></span><br><span class="line">    <span class="keyword">if</span> end &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 先把当前需要比较字符获取出来</span></span><br><span class="line">    <span class="keyword">if</span> end - tempLen + <span class="number">1</span> &gt;= <span class="number">0</span>:</span><br><span class="line">        temp = target[end - tempLen + <span class="number">1</span>:end + <span class="number">1</span>]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        temp = target[<span class="number">0</span>:end + <span class="number">1</span>]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">    <span class="comment"># len=1表示当前取的字段只剩一个字，不管是否匹配成功都加入结果</span></span><br><span class="line">    <span class="keyword">if</span> tempLen == <span class="number">1</span>:</span><br><span class="line">        result.append(temp)</span><br><span class="line">        recursionMatchSolve(maxLen, dic, target, end - <span class="number">1</span>, maxLen, result)</span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 记得return</span></span><br><span class="line">    <span class="comment"># 比较词典中的词</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> dic:</span><br><span class="line">        <span class="keyword">if</span> i == temp:</span><br><span class="line">            result.append(i)</span><br><span class="line">            recursionMatchSolve(maxLen, dic, target, end - tempLen, maxLen, result)  <span class="comment"># 匹配成功就重置len</span></span><br><span class="line">            <span class="keyword">return</span>  <span class="comment"># 记得return</span></span><br><span class="line">    recursionMatchSolve(maxLen, dic, target, end, tempLen - <span class="number">1</span>, result)  <span class="comment"># 匹配失败</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 迭代写法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">iterationMatch</span>(<span class="params">maxLen, dic, target</span>):</span><br><span class="line">    result = []</span><br><span class="line">    end = <span class="built_in">len</span>(target) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 循环中写终止条件</span></span><br><span class="line">    <span class="keyword">while</span> end &gt;= <span class="number">0</span>:</span><br><span class="line">        tempLen = maxLen</span><br><span class="line">        found = <span class="literal">False</span>  <span class="comment"># 记录本次是否匹配成功，匹配成功则退出下面循环，不然就会一直找到tempLen=0，中途找到结果会出问题</span></span><br><span class="line">        <span class="keyword">while</span> tempLen &gt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> end - tempLen + <span class="number">1</span> &gt;= <span class="number">0</span>:</span><br><span class="line">                temp = target[end - tempLen + <span class="number">1</span>:end + <span class="number">1</span>]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp = target[<span class="number">0</span>:end + <span class="number">1</span>]  <span class="comment"># 切片左闭右开</span></span><br><span class="line">            <span class="keyword">if</span> tempLen == <span class="number">1</span>:</span><br><span class="line">                result.append(temp)</span><br><span class="line">                end = end - <span class="number">1</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> dic:</span><br><span class="line">                <span class="comment"># 匹配成功就跳出本次循环</span></span><br><span class="line">                <span class="keyword">if</span> i == temp:</span><br><span class="line">                    result.append(temp)</span><br><span class="line">                    end = end - tempLen</span><br><span class="line">                    found = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 找到结果退出循环</span></span><br><span class="line">            <span class="keyword">if</span> found:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 暂时找不到</span></span><br><span class="line">            tempLen = tempLen - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 翻转列表</span></span><br><span class="line">    result.reverse()</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>



<h5 id="基于统计的中文分词方法"><a href="#基于统计的中文分词方法" class="headerlink" title="基于统计的中文分词方法"></a>基于统计的中文分词方法</h5><p><strong>基本思路和特点</strong></p>
<p>利用字与字间、词与词间的同现频率作为分词的依据；<br>需要大规模的训练文本, 用来训练模型参数；<br>优点：不受应用领域的限制；<br>缺点：训练文本的选择影响分词结果。</p>
<h6 id="概率最大分词法（n元语法模型）"><a href="#概率最大分词法（n元语法模型）" class="headerlink" title="概率最大分词法（n元语法模型）"></a>概率最大分词法（n元语法模型）</h6><p><strong>概率最大分词法可以通过不同的语法模型完成，这里分别给出不同语法模型的介绍（下面也给出了因为数据缺乏而必需采取平滑算法），同时给出基于二元语法模型的概率最大分词的代码</strong></p>
<ul>
<li><strong>采用一元语法模型（独立性假设）</strong></li>
</ul>
<p>每个词的出现是独立的，与其他词的出现无关</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310111118921.png" alt="image-20231011111829845"></p>
<p><strong>手算展示例子</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310112137328.png" alt="image-20231011213715214"></p>
<ul>
<li><strong>采用二元语法模型（马尔可夫假设）（代码）</strong></li>
</ul>
<p>每个词的发生概率取决于前一个词</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310111119922.png" alt="image-20231011111903875"></p>
<p><strong>举例</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310172301038.png" alt="image-20231017230128865"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310172301971.png" alt="image-20231017230155902"></p>
<p><strong>手算展示例子</strong></p>
<ol>
<li><p>对一个待分词的字串S,按照从左到右的顺序取出全部候选词𝑤𝟏, 𝑤2, … , 𝑤𝒏;（这里例子为”结合成分子时“）</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>候选词</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>结</td>
<td></td>
<td></td>
</tr>
<tr>
<td>0</td>
<td>结合</td>
<td></td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>合</td>
<td></td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>合成</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>成</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>成分</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>分</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>分子</td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>子</td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>时</td>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
<li><p>计算每个候选词的概率值𝒑 (𝑤𝒊), 记录每个候选词的全部左邻词</p>
<p>（候选词的概率可以从语料库中获得，从左往右寻找到达当前编码的前一个位置的所有词）</p>
<p><strong>（左邻词就是左边相邻的一个词）</strong></p>
<table>
<thead>
<tr>
<th>序号</th>
<th>候选词</th>
<th>候选词概率</th>
<th>左邻词</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>结</td>
<td>0.0037</td>
<td>&#x2F;</td>
</tr>
<tr>
<td>0</td>
<td>结合</td>
<td>0.0353</td>
<td>&#x2F;</td>
</tr>
<tr>
<td>1</td>
<td>合</td>
<td>0.0049</td>
<td>结</td>
</tr>
<tr>
<td>1</td>
<td>合成</td>
<td>0.0006</td>
<td>结</td>
</tr>
<tr>
<td>2</td>
<td>成</td>
<td>0.0423</td>
<td>合，结合</td>
</tr>
<tr>
<td>2</td>
<td>成分</td>
<td>0.0023</td>
<td>合，结合</td>
</tr>
<tr>
<td>3</td>
<td>分</td>
<td>0.0312</td>
<td>合成，成</td>
</tr>
<tr>
<td>3</td>
<td>分子</td>
<td>0.0038</td>
<td>合成，成</td>
</tr>
<tr>
<td>4</td>
<td>子</td>
<td>0.001</td>
<td>分，成分</td>
</tr>
<tr>
<td>5</td>
<td>时</td>
<td>0.1043</td>
<td>子，分子</td>
</tr>
</tbody></table>
</li>
<li><p>计算每个候选词的累积概率，并找出每个词的最佳左邻词</p>
<p>（累积概率最大的候选词为最佳左邻词）</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>序号</th>
<th>候选词</th>
<th>候选词概率</th>
<th>左邻词</th>
<th>累积概率</th>
<th>最佳左邻词</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>结</td>
<td>0.0037</td>
<td>&#x2F;</td>
<td>0.0037</td>
<td>&#x2F;</td>
</tr>
<tr>
<td>0</td>
<td>结合</td>
<td>0.0353</td>
<td>&#x2F;</td>
<td>0.0353</td>
<td>&#x2F;</td>
</tr>
<tr>
<td>1</td>
<td>合</td>
<td>0.0049</td>
<td>结</td>
<td>0.00001813</td>
<td>结</td>
</tr>
<tr>
<td>1</td>
<td>合成</td>
<td>0.0006</td>
<td>结</td>
<td>0.00000222</td>
<td>结</td>
</tr>
<tr>
<td>2</td>
<td>成</td>
<td>0.0423</td>
<td>合，结合</td>
<td>0.00149319</td>
<td>结合</td>
</tr>
<tr>
<td>2</td>
<td>成分</td>
<td>0.0023</td>
<td>合，结合</td>
<td>0.00008119</td>
<td>结合</td>
</tr>
<tr>
<td>3</td>
<td>分</td>
<td>0.0312</td>
<td>合成，成</td>
<td>0.000046587528</td>
<td>成</td>
</tr>
<tr>
<td>3</td>
<td>分子</td>
<td>0.0038</td>
<td>合成，成</td>
<td>0.000005674122</td>
<td>成</td>
</tr>
<tr>
<td>4</td>
<td>子</td>
<td>0.001</td>
<td>分，成分</td>
<td>0.00000008119</td>
<td>成分</td>
</tr>
<tr>
<td>5</td>
<td>时</td>
<td>0.1043</td>
<td>子，分子</td>
<td>0.0000005918109246</td>
<td>分子</td>
</tr>
</tbody></table>
<p>结：没有左邻词，累积概率为自己的概率0.0037</p>
<p>结合：没有左邻词，累积概率为自己的概率0.0353</p>
<p>合：有一个左邻词是结，概率为0.0049×0.0037&#x3D;0.00001813</p>
<p>合成：有一个左邻词是结，概率为0.0006×0.0037&#x3D;0.00000222</p>
<p>成：有两个左邻词，首先看合，概率为0.0423×0.00001813&#x3D;0.000000766899；再看结合，概率为0.0423×0.0353&#x3D;0.00149319，选最大累积概率确定最优左邻词为结合</p>
<p>成分：有两个左邻词，首先看合，概率为0.0023×0.00001813&#x3D;0.000000041699；再看结合，概率为0.0023×0.0353&#x3D;0.00008119，选最大累积概率确定最优左邻词为结合</p>
<p>分：有两个左邻词，首先看合成，概率为0.0312×0.00000222&#x3D;0.000000069264；再看成，概率为0.0312×0.00149319&#x3D;0.000046587528，选最大累积概率确定最优左邻词为成</p>
<p>分子：有两个左邻词，首先看合成，概率为  0.0038×0.00000222&#x3D;0.000000008436；再看成，概率为  0.0038×0.00149319&#x3D;0.000005674122，选最大累积概率确定最优左邻词为成</p>
<p>子：有两个左邻词，首先看分，概率为0.001×0.000046587528&#x3D;0.000000046587528；再看成分，概率为0.001×  0.00008119&#x3D;0.00000008119，选最大累积概率确定最优左邻词为成分</p>
<p>时：有两个左邻词，首先看子，概率为0.1043×0.00000008119&#x3D;0.000000008468117；再看分子，概率为0.1043×0.000005674122&#x3D;0.0000005918109246，选最大累积概率确定最优左邻词为分子</p>
<ol start="4">
<li><p>找终点词</p>
<p><strong>这句话最后一个字为时，这里只有一种结果，如果有两种情况，如子时和时出现的时候，就看哪个累积概率大就选哪个</strong></p>
</li>
<li><p>输出分词结果</p>
<p>选时，它的最佳左邻词为分子，选分子，分子最佳左邻词为成，选成，成的最佳左邻词为结合，选结合</p>
<p>最后得出结果为结合&#x2F;成&#x2F;分子&#x2F;时</p>
</li>
</ol>
<p><strong>算法描述</strong></p>
<p>（从上方的手算过程可以看出，这个算法思想是使用动态规划算法来实现，即最优路径中的第i个词wi的累计概率等于它的左相邻词wi-1的累积概率乘以wi自身的概率）</p>
<ol>
<li>对一个待分词的字串S,按照从左到右的顺序取出全部<br>候选词𝑤𝟏, 𝑤2, … , 𝑤𝒏;</li>
<li>计算每个候选词的概率值𝒑 𝑤𝒊 记录每个候选词的全部<br>左邻词;</li>
<li>计算每个候选词的累计概率，累计概率最大的候选词<br>为最佳左邻词;</li>
<li>如果当前词𝑤𝒏是字串的尾词,且累计概率𝒑 𝑤𝒏 最大，<br>则𝑤𝒏是S的终点词；</li>
<li>从𝑤𝒏开始，按照从右到左顺序，依次将每个词的最佳<br>左邻词输出，即S的分词结果.</li>
</ol>
<p><strong>代码（个人书写）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先要有候选词和候选词的概率字典，这个外部传进来，规定字典样式，字典第一列为正确词语，第二列为概率</span></span><br><span class="line"><span class="comment"># dic为字典，target为待切分语料</span></span><br><span class="line"><span class="comment"># 基于二元语法模型的概率最大分词方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">match</span>(<span class="params">dic, target</span>):</span><br><span class="line">    result = []</span><br><span class="line">    recordList = initList(dic, target)</span><br><span class="line"></span><br><span class="line">    dp(target, recordList)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 逆着找最大值，找到当前列的最大值，最大值说明当前这种情况是出现概率最大的，添加进结果列表，然后得到截断的行坐标，继续往前找即可</span></span><br><span class="line">    j = <span class="built_in">len</span>(target) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &gt;= <span class="number">0</span>:</span><br><span class="line">        tempMax = <span class="number">0</span></span><br><span class="line">        tempMaxRow = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(j + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> recordList[i][j] &gt;= tempMax:</span><br><span class="line">                tempMax = recordList[i][j]</span><br><span class="line">                tempMaxRow = i</span><br><span class="line">        result.append(target[tempMaxRow:j + <span class="number">1</span>])</span><br><span class="line">        j = tempMaxRow - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    result.reverse()  <span class="comment"># 翻转list</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一个记录列表，targetLen为字符串长度，生成targetLen*targetLen的列表，然后根据字典填充记录列表并返回</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initList</span>(<span class="params">dic, target</span>):</span><br><span class="line">    targetLen = <span class="built_in">len</span>(target)</span><br><span class="line">    recordList = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(targetLen)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(targetLen)]  <span class="comment"># 创建一个二维列表，初始化为0</span></span><br><span class="line">    dicLen = <span class="built_in">len</span>(dic)  <span class="comment"># 字典行数，列数为len(dic[0])</span></span><br><span class="line">    <span class="comment"># 不断切分语料并匹配词典概率</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(targetLen):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(targetLen):</span><br><span class="line">            temp = target[i:j + <span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 查看字典有没有切分的这个情况的词，有就把概率填充进记录列表</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(dicLen):</span><br><span class="line">                <span class="keyword">if</span> temp == dic[k][<span class="number">0</span>]:</span><br><span class="line">                    recordList[i][j] = dic[k][<span class="number">1</span>]  <span class="comment"># 第二列为对应词的概率</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> recordList</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 动态规划填充记录列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dp</span>(<span class="params">target, recordList</span>):</span><br><span class="line">    targetLen = <span class="built_in">len</span>(target)</span><br><span class="line">    <span class="comment"># 自左往右，自下往上填表</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(targetLen):</span><br><span class="line">        <span class="comment"># i+1是因为当独切分一个字符的概率要么给出要么为0，不用计算了</span></span><br><span class="line">        <span class="comment"># range左闭右开</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(j, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(i, j):</span><br><span class="line">                <span class="keyword">if</span> recordList[i][k] * recordList[k + <span class="number">1</span>][j] &gt; recordList[i][j]:</span><br><span class="line">                    recordList[i][j] = recordList[i][k] * recordList[k + <span class="number">1</span>][j]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ProbabilisticMaximumWordSegmentationMethod <span class="keyword">as</span> Method</span><br><span class="line"></span><br><span class="line">dic = [[<span class="string">&#x27;结&#x27;</span>, <span class="number">0.0037</span>],</span><br><span class="line">       [<span class="string">&#x27;结合&#x27;</span>, <span class="number">0.0353</span>],</span><br><span class="line">       [<span class="string">&#x27;合&#x27;</span>, <span class="number">0.0049</span>],</span><br><span class="line">       [<span class="string">&#x27;合成&#x27;</span>, <span class="number">0.0006</span>],</span><br><span class="line">       [<span class="string">&#x27;成&#x27;</span>, <span class="number">0.0423</span>],</span><br><span class="line">       [<span class="string">&#x27;成分&#x27;</span>, <span class="number">0.0023</span>],</span><br><span class="line">       [<span class="string">&#x27;分&#x27;</span>, <span class="number">0.0312</span>],</span><br><span class="line">       [<span class="string">&#x27;分子&#x27;</span>, <span class="number">0.0038</span>],</span><br><span class="line">       [<span class="string">&#x27;子&#x27;</span>, <span class="number">0.001</span>],</span><br><span class="line">       [<span class="string">&#x27;时&#x27;</span>, <span class="number">0.1043</span>]]</span><br><span class="line">target = <span class="string">&#x27;结合成分子时&#x27;</span></span><br><span class="line"></span><br><span class="line">result = Method.<span class="keyword">match</span>(dic, target)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">    <span class="built_in">print</span>(i, end=<span class="string">&quot;|&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li><strong>n元语法模型</strong></li>
</ul>
<p>每个词的发生概率取决于前n-1个词</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310111119740.png" alt="image-20231011111958695"></p>
<p>事实上绝大多数历史根本不可能在训练数据中出现，为此，可以通过划分等价类的方法降低历史的数目，等价划分降低参数后的语言模型称为n元语法或n元文法**(n-gram)**，通常n不会太大，否则等价类太多，无法具体实现！</p>
<h6 id="数据平滑"><a href="#数据平滑" class="headerlink" title="数据平滑"></a>数据平滑</h6><p>平滑技术就是用来解决0概率问题，其基本思想是“劫富济贫”，提高低概率，降低高概率，尽量使得概率分布趋于均匀！（当分子为0的时候就会出现0概率问题，但这时候整块结果就会为0，影响整体结果）</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310172306061.png" alt="image-20231017230643007"></p>
<p><strong>例子</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310172307625.png" alt="image-20231017230731563"></p>
<h5 id="基于神经网络的中文分词方法"><a href="#基于神经网络的中文分词方法" class="headerlink" title="基于神经网络的中文分词方法"></a>基于神经网络的中文分词方法</h5><p><strong>基本思路和特点</strong></p>
<p>参数量大、模型训练时间相对较长等。</p>
<hr>
<h4 id="词性标注"><a href="#词性标注" class="headerlink" title="词性标注"></a>词性标注</h4><h5 id="相关知识-2"><a href="#相关知识-2" class="headerlink" title="相关知识"></a>相关知识</h5><p><strong>MM（马尔可夫链）</strong></p>
<p><a href = "#MM">马尔可夫</a>链有显马尔可夫链（VMM）和<a href = "#HMM">隐马尔可夫链（HMM）</a></p>
<ul>
<li><p><strong>马尔可夫</strong>	<a name = "MM"></a></p>
<p>假设某系统有N个有限状态 S&#x3D;{s1,s2,…,sN} ，随着时间的推移，系统将从某一个状态转移到另一个状态。</p>
<p>X&#x3D;{x1,x2,…,xT}是一个<strong>取值于有限状态集合S</strong>的随机变量序列，随机变量的取值为状态集S的某个状态，假定在时间t的状态记为 xt ，xt∈S,t&#x3D;1,2,…,T。那么这里X称为一阶马尔可夫链，或称具有马尔可夫性质，则系统在时间t处于状态sj的概率取决于它在时间1,2,3,…,t−1的状态，其概率为</p>
</li>
</ul>
<p>$$<br>P（xt &#x3D; sj | x(t-1) &#x3D; sj,x(t-2) &#x3D; sk）<br>$$</p>
<p>即在特定情况下，系统在时间t的状态下只与其在时间t-1的状态相关（二元语法模型），该随机过程称为一阶马尔可夫过程。</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271032493.png" alt="image-20231027103216239"></p>
<p>​		<strong>注：状态转移矩阵的每一行所有列元素的概率和为1</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271033701.png" alt="image-20231027103324549"></p>
<p><em>例2</em></p>
<p>假设有如下转移矩阵</p>
<p>​		v		n		p</p>
<p>v	0.1	0.8		0.1</p>
<p>n	0.8	0.01	0.19</p>
<p>p	0.9	0.05	0.05</p>
<p>那么P(n,v,p,n|M) &#x3D; P(n) * P(v|n) * P(p|v) * P(n|p) &#x3D; 1 * 0.8 *0.1 * 0.05 &#x3D; 0.004</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271042015.png" alt="image-20231027104218854"></p>
<ul>
<li><strong>隐马尔可夫模型HMM</strong>	<a name = "HMM"></a></li>
</ul>
<p>隐马尔可夫模型（Hidden Markov Model，HMM）是一种概率模型，用于解决序列预测问题</p>
<p>在马尔可夫模型中，每个状态代表了一个可观察到的事件。如：天气马尔可夫模型，前提是，第二天是天气是可以观察到的。如果知道某个事件的观察序列，是可以使用一个马尔可夫模型来计算；但是，有时候有些事件是不可以直接观测到的。例如：如果一个盲人，他不能通过观察天气来预测天气，他只能通过摸水藻的干湿程度来间接预测天气。这时，水藻的干湿就是可观察事件，其状态为可观察状态；而天气则是隐状态；</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271055416.png" alt="image-20231027105528232"></p>
<p><strong>隐含马尔可夫模型被认为是解决大多数自然语言处理问题最快速、有效的方法</strong>；</p>
<p>应用：语音识别、NLP中的分词、词性标注、计算机视觉中的动作识别等；成功解决了复杂的语音识别、机器翻译等问题；</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271059853.png" alt="image-20231027105902710"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271100620.png" alt="image-20231027110042426"></p>
<ol>
<li>评估问题。</li>
</ol>
<p>给定观测序列 O&#x3D;O1O2O3…Ot和模型参数λ&#x3D;(A,B,π)，怎样有效计算某一观测序列的概率，进而可对该HMM做出相关评估。例如，已有一些模型参数各异的HMM，给定观测序列O&#x3D;O1O2O3…Ot，我们想知道哪个HMM模型最可能生成该观测序列。通常我们利用forward算法分别计算每个HMM产生给定观测序列O的概率，然后从中选出最优的HMM模型。</p>
<p>这类评估的问题的一个经典例子是语音识别。在描述语言识别的隐马尔科夫模型中，每个单词生成一个对应的HMM，每个观测序列由一个单词的语音构成，单词的识别是通过评估进而选出最有可能产生观测序列所代表的读音的HMM而实现的。</p>
<p>2.解码问题</p>
<p>给定观测序列 O&#x3D;O1O2O3…Ot 和模型参数λ&#x3D;(A,B,π)，怎样寻找某种意义上最优的隐状态序列。在这类问题中，我们感兴趣的是马尔科夫模型中隐含状态，这些状态不能直接观测但却更具有价值，通常利用Viterbi算法来寻找。</p>
<p>这类问题的一个实际例子是中文分词，即把一个句子如何划分其构成才合适。例如，句子“发展中国家”是划分成“发展-中-国家”，还是“发展-中国-家”。这个问题可以用隐马尔科夫模型来解决。句子的分词方法可以看成是隐含状态，而句子则可以看成是给定的可观测状态，从而通过建HMM来寻找出最可能正确的分词方法。</p>
<ol start="3">
<li>学习问题。</li>
</ol>
<p>即HMM的模型参数λ&#x3D;(A,B,π)未知，如何调整这些参数以使观测序列O&#x3D;O1O2O3…Ot的概率尽可能的大。通常使用Baum-Welch算法以及Reversed Viterbi算法解决。</p>
<p>怎样调整模型参数λ&#x3D;(A,B,π)，使观测序列 O&#x3D;O1O2O3…Ot的概率最大？</p>
<p>针对以下三个问题，人们提出了相应的算法</p>
<ol>
<li>评估问题： 直接计算法（概念上可行，计算上不科学）、前向算法、后向算法</li>
</ol>
<p>​	当然也存在穷举搜索算法（就是列举出所有可能性，就是把所有组合路径找出来，计算每条路径的概率，当序列词数比较多的时候就会耗费很多时间，为了避免耗费过多时间就会使用前向算法）</p>
<ol start="2">
<li>解码问题：</li>
</ol>
<p>​	<a href = "#viterbi">Viterbi算法</a>：使用动态规划求解概率最大（最优）路径。</p>
<p>​	近似算法：选择每一时刻最有可能出现的状态，从而得到一个状态序列。</p>
<ol start="3">
<li>学习问题： Baum-Welch算法(向前向后算法)、监督学习算法</li>
</ol>
<h5 id="词性标注相关概念"><a href="#词性标注相关概念" class="headerlink" title="词性标注相关概念"></a>词性标注相关概念</h5><p><strong>词性标注的定义</strong></p>
<p>即判定给定句子中每个词的语法范畴，确定其词性并加以标注的过程。</p>
<p>如果词w存在两个或两个以上的词性，则词w具有<strong>词性标注歧义</strong>。</p>
<p><strong>词性标注的必要性</strong></p>
<p>汉语由于缺乏语法形态变化，词的应用非常灵活，词类兼类现象特别多，也特别复杂，因此需要做词性标注。</p>
<p>自然语言中普遍存在<strong>词类兼类</strong>现象<strong>（一个词可做多个词性的现象）</strong>，正因为存在词类兼类的问题，所以在对词切分时必然要注明词的词性，于是就出现了词性标注</p>
<p>例：他是总<em>编辑</em>（名词）             他正在<em>编辑</em>这本书（动词）</p>
<p><strong>应用</strong></p>
<p>词性标注是一个比较活跃的研究领域，应用广泛，如：口语识别与生成、机器翻译、信息检索和词典编撰等</p>
<p><strong>词性标准的研究方法</strong></p>
<ul>
<li>基于规则方法进行标注</li>
<li>统计方法进行标注</li>
<li>规则与统计方法结合进行标注</li>
<li>基于转换的错误驱动学习</li>
</ul>
<h5 id="基于规则的词性标注"><a href="#基于规则的词性标注" class="headerlink" title="基于规则的词性标注"></a>基于规则的词性标注</h5><p><strong>原理</strong></p>
<p>利用事先制定好的规则对具有多个词性的词进行消歧，最后保留一个正确的词性。</p>
<p><strong>步骤</strong></p>
<ol>
<li>对词性歧义建立单独的标注规则库；</li>
<li>标注时，查词典，如果某个词具有多个词性，则查找规则库，对具有相同模式的歧义进行排歧，否则保留。</li>
<li>程序和规则库是独立的两个部分。</li>
</ol>
<p><strong>举例</strong></p>
<p>一把青菜(量词)                                 </p>
<p>我把书放在冰箱上(动词)</p>
<p>要求：要对这两句话进行切分并标注词性。</p>
<p>实现步骤：</p>
<ol>
<li><p>已建词典中有：     把  v,l</p>
</li>
<li><p>已建规则库中有：</p>
</li>
</ol>
<p>   规则1：如果当前词的前相邻词的词性为s，则该词的词性为l ，如果当前词的前相邻词的词性为n，则该词的词性为v</p>
<ol start="3">
<li><p>算法：             </p>
<p>用MM方法来切分句子，边切边标注词性。             </p>
<p>词性标注时，当切分到‘把’时，有两个词性，怎么办？</p>
<p>到规则库中去寻找相同模式的规则，如这里的规则1恰好满足，所以这里的“把”取q词性。</p>
</li>
</ol>
<h5 id="基于统计的词性标注"><a href="#基于统计的词性标注" class="headerlink" title="基于统计的词性标注"></a>基于统计的词性标注</h5><p><strong>基本思路</strong></p>
<p>初始：令W&#x3D;w1w2…wn是由n个词组成的词串，T&#x3D;t1t2…tn是词串W对应的词性标注串，其中tk是wk的词性标注；</p>
<p>目标：计算使得条件概率 P(T|W)值最大的词性标注序列T’</p>
<p>思路：</p>
<ul>
<li><p>根据贝叶斯公式：P(T|W)&#x3D; P(T) P(W|T)&#x2F; P(W)</p>
</li>
<li><p>.由于词串不变,p(W)不影响总的概率值，因此继续简化为：<strong>P(T|W)&#x3D; P(T) P(W|T)</strong></p>
</li>
<li><p>其中P(T)&#x3D; P(t1|t0) P(t2|t1,t0)… P(ti|ti-1..)</p>
</li>
<li><p>根据2元语法模型，可得：**P(T)&#x3D; P(t1|t0) P(t2|t1)… P(ti|ti-1) **</p>
</li>
</ul>
<p><strong>P(ti|ti-1)&#x3D;训练语料中ti出现在ti-1之后的次数 &#x2F; 训练语料中ti-1出现的总次数</strong></p>
<ul>
<li>根据乘法公式：P(W|T)&#x3D; P(w1|t1) P(w2|t2,t1)… P(wi|ti,ti-1…,t1)</li>
<li>上式使用1元语法模型：<strong>P(W|T)&#x3D; P(w1|t1) P(w2|t2)… P(wi|ti)</strong></li>
</ul>
<p><strong>P(wi|ti)&#x3D;训练语料中wi的词性被标记为ti的次数 &#x2F; 训练语料中ti出现的总次数</strong></p>
<p><strong>CLAWS算法</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310172350012.png" alt="image-20231017235037944"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310172351455.png" alt="image-20231017235100395"></p>
<p><strong>VOLSUNGA算法</strong></p>
<p>对CLAWS算法进行改进后得到</p>
<p>CLAWS算法中最佳路径的定义为N个可能的排列中概率乘积最大的那条路径</p>
<p>VOLSUNGA算法从左往右，对于当前考虑的词，只保留通往该词的每个词类的最佳路径，然后继续将这些路径与下个词的所有词类标记进行匹配，分别找出通往这个词的每个标记的最佳路径，后面的词依次重复</p>
<p><strong>下面是跟马尔可夫链相关的算法</strong></p>
<h6 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h6><p><strong>解决问题</strong></p>
<p>给定一个隐马尔科夫模型M&#x3D;(A,B)，以及一个观测序列O，计算P(O|M) (A表示转移概率，B表示发射概率)例如，给定一个天气的HMM模型，计算某个观测序列{dry,damp,soggy}的概率？即：   P(dry,damp,soggy|A,B)</p>
<p><strong>描述</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271211679.png" alt="image-20231027121142439"></p>
<p><em>个人理解：</em>前向算法是为了评估HMM模型的，返回一个概率以评估HMM模型，以找到最好的HMM模型，对于概率矩阵，第一列跟维特比算法一样，<strong>初始概率  * 发射概率</strong>，从第二列开始跟维特比算法有区别，对于每列，列中每个元素等于<strong>前一列每个元素 * 转移概率求和，然后再 * 发射概率</strong>，最后返回最后一列的所有概率的和。</p>
<h6 id="HMM-Viterbi"><a href="#HMM-Viterbi" class="headerlink" title="HMM+Viterbi"></a>HMM+Viterbi</h6><p><strong>维特比算法思想</strong> <a name = "viterbi"></a></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271106664.png" alt="image-20231027110654483"></p>
<p>这样每个节点保存的是到当前节点的局部最优概率；依据最后一个时刻中概率最高的状态，逆向找其路径中的上一个最大部分最优路径，从而找到整个最优路径。</p>
<p><strong>隐马尔可夫模型+维特比算法在词性标注中的应用</strong>  </p>
<p>（<a href = "#hmm+viterbi">代码</a>）</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271108872.png" alt="image-20231027110815670"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271113235.png" alt="image-20231027111331942"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271151495.png" alt="image-20231027115108390"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271151959.png" alt="image-20231027115120860"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271151224.png" alt="image-20231027115135080"></p>
<p><strong>具体示例和代码</strong>	<a name = "hmm+viterbi"></a></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271155989.png" alt="image-20231027115516565"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271201410.png" alt="image-20231027120114234"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271201210.png" alt="image-20231027120138032"></p>
<p><strong>这里为了代码书写方便，代码中处理的发射矩阵为下图，只需获取对应坐标即得到发射矩阵的值</strong></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202310271201469.png" alt="image-20231027120158294"></p>
<p><em>代码</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化相关</span></span><br><span class="line"><span class="comment"># 按照定义发射矩阵的行对应隐序列全部序列，列对应所有给定的可观测值，这样每一行的列全部概率想加为1</span></span><br><span class="line"><span class="comment"># 这里按照自己实际代码书写把传出的发射矩阵行坐标为对应隐序列全部序列，列为观测序列，在后续乘上观测序列的时候直接通过坐标值获取即可，也可以建立字典，某个词对应列坐标保存起来</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转置输入的发射矩阵得到行为隐序列，列为观测序列的矩阵，并进行数据平滑和归一化</span></span><br><span class="line"><span class="comment"># initObserveList为给定所有观测序列，observeList为观测序列，initMatrix为给定矩阵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getEmissionMatrix</span>(<span class="params">initObserveList, initMatrix, observeList</span>):</span><br><span class="line">    <span class="comment"># 将字母转换成小写，方便后面对比观测序列和所有观测序列元素是否一样</span></span><br><span class="line">    lowerInitObserveList = [<span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initObserveList))]</span><br><span class="line"></span><br><span class="line">    lowerObserveList = [<span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(observeList))]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initObserveList)):</span><br><span class="line">        lowerInitObserveList[i] = <span class="built_in">str</span>(initObserveList[i]).lower()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(observeList)):</span><br><span class="line">        lowerObserveList[i] = <span class="built_in">str</span>(observeList[i]).lower()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先创建列多少元素再创建行，转置矩阵</span></span><br><span class="line">    tempMatrix = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix))] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix[<span class="number">0</span>]))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转置矩阵后，进行数据平滑，然后得到定义的发射矩阵</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix[<span class="number">0</span>])):</span><br><span class="line">            tempMatrix[j][i] = initMatrix[i][j] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tempMatrix)):</span><br><span class="line">        tempSum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tempMatrix[<span class="number">0</span>])):</span><br><span class="line">            tempSum = tempSum + tempMatrix[i][j]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tempMatrix[<span class="number">0</span>])):</span><br><span class="line">            tempMatrix[i][j] = tempMatrix[i][j] / tempSum</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据观测序列创建对应的发射矩阵，就是行为隐序列，列为观测序列的矩阵，按照自己代码需求不删除重复列，但是概率计算正确了</span></span><br><span class="line">    emissionMatrix = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(observeList))] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix[<span class="number">0</span>]))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据观测序列和初始提供的发射矩阵转置后的矩阵的列名确认所需发射矩阵</span></span><br><span class="line">    <span class="keyword">for</span> j1 <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lowerObserveList)):</span><br><span class="line">        <span class="keyword">for</span> j2 <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lowerInitObserveList)):</span><br><span class="line">            <span class="keyword">if</span> lowerInitObserveList[j2] == lowerObserveList[j1]:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tempMatrix)):</span><br><span class="line">                    emissionMatrix[i][j1] = tempMatrix[i][j2]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> emissionMatrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对转移矩阵进行数据平滑和归一化</span></span><br><span class="line"><span class="comment"># initMatrix为给定矩阵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTransferMatrix</span>(<span class="params">initMatrix</span>):</span><br><span class="line">    transferMatrix = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix[<span class="number">0</span>]))] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix))]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix)):</span><br><span class="line">        tempSum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(initMatrix[<span class="number">0</span>])):</span><br><span class="line">            transferMatrix[i][j] = initMatrix[i][j] + <span class="number">1</span>  <span class="comment"># 加1数据平滑</span></span><br><span class="line">            tempSum = tempSum + transferMatrix[i][j]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(transferMatrix[<span class="number">0</span>])):</span><br><span class="line">            transferMatrix[i][j] = transferMatrix[i][j] / tempSum  <span class="comment"># 每行的各概率加起来为1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transferMatrix</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入发射矩阵和转移矩阵</span></span><br><span class="line"><span class="comment"># initChanceList为初始概率矩阵，emissionMatrix为发射矩阵，transferMatrix为转移矩阵，hideList为隐序列</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hmmViterbi</span>(<span class="params">initChanceList, emissionMatrix, transferMatrix, hideList</span>):</span><br><span class="line">    <span class="comment"># 保存结果</span></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 观测序列长度，也就是发射矩阵的列数</span></span><br><span class="line">    observeLen = <span class="built_in">len</span>(emissionMatrix[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 隐序列长度，也就是发射矩阵的行数</span></span><br><span class="line">    hideLen = <span class="built_in">len</span>(emissionMatrix)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># viterbi矩阵 记录当前概率最大矩阵,行数为隐序列长度，对应隐序列每个词，列数为观测序列长度，对于观测序列每个词</span></span><br><span class="line">    viterbiList = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(observeLen)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(hideLen)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backPoint矩阵 记录得到viterbi当前最大值对应上一列的坐标（以列循环） 大小和viterbi大小一样</span></span><br><span class="line">    backPoint = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(observeLen)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(hideLen)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 核心部分</span></span><br><span class="line">    <span class="comment"># 初始viterbi矩阵和backPoint矩阵，初始第一列</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hideLen):</span><br><span class="line">        viterbiList[i][<span class="number">0</span>] = initChanceList[i] * emissionMatrix[i][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从第二列开始</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, observeLen):</span><br><span class="line">        <span class="comment"># 每列的每个元素，就是第几行</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hideLen):</span><br><span class="line">            <span class="comment"># 当前要填入的值为前一列转移到当前的最大概率，tempMax记录当前最大值</span></span><br><span class="line">            tempMax = -<span class="number">1</span></span><br><span class="line">            <span class="comment"># 前一列的每个值乘上当前待填入值的点的发射概率,发射矩阵对应坐标跟viterbi矩阵当前坐标一样,还要乘上转移概率，转移概率矩阵对应坐标为(k,j)</span></span><br><span class="line">            <span class="comment"># 最大值记录下来，一次遍历最大值填入，同时记录得出最大值的乘法中上列值的横坐标</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(hideLen):</span><br><span class="line">                <span class="keyword">if</span> viterbiList[k][j - <span class="number">1</span>] * emissionMatrix[i][j] * transferMatrix[k][i] &gt;= tempMax:</span><br><span class="line">                    tempMax = viterbiList[k][j - <span class="number">1</span>] * emissionMatrix[i][j] * transferMatrix[k][i]</span><br><span class="line">                    backPoint[i][j] = k</span><br><span class="line">            viterbiList[i][j] = tempMax</span><br><span class="line"></span><br><span class="line">    <span class="comment"># tempMax保存最后一列最大值，tempMaxIndex保存最后一列最大值的横坐标，tempIndex保存下一次回溯的横坐标</span></span><br><span class="line">    tempMax = <span class="number">0</span></span><br><span class="line">    tempMaxIndex = <span class="number">0</span></span><br><span class="line">    tempIndex = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hideLen):</span><br><span class="line">        <span class="keyword">if</span> viterbiList[i][observeLen - <span class="number">1</span>] &gt;= tempMax:</span><br><span class="line">            tempMax = viterbiList[i][observeLen - <span class="number">1</span>]</span><br><span class="line">            tempMaxIndex = i</span><br><span class="line">            tempIndex = backPoint[i][observeLen - <span class="number">1</span>]</span><br><span class="line">    result.append(hideList[tempMaxIndex])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从倒数第二行开始回溯根据backPoint矩阵寻找结果</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(observeLen - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        result.append(hideList[tempIndex])</span><br><span class="line">        tempIndex = backPoint[tempIndex][j]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出viterbi矩阵</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;viterbi矩阵如下:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(viterbiList)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(viterbiList[<span class="number">0</span>])):</span><br><span class="line">            <span class="built_in">print</span>(viterbiList[i][j], end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出backPoint矩阵</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;backPoint矩阵如下:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(backPoint)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(backPoint[<span class="number">0</span>])):</span><br><span class="line">            <span class="built_in">print</span>(backPoint[i][j], end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    result.reverse()  <span class="comment"># 翻转</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> InitUtil</span><br><span class="line"><span class="keyword">import</span> HMMAndViterbi</span><br><span class="line"></span><br><span class="line"><span class="comment">#  观测序列  分词后的语句  &#123;The bear is on the move&#125;</span></span><br><span class="line">observeList = [<span class="string">&#x27;The&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;on&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;move&#x27;</span>]</span><br><span class="line"></span><br><span class="line">observeLen = <span class="built_in">len</span>(observeList)  <span class="comment"># 观测序列长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐序列 词性 &#123;AT BEZ IN NN VB PERIOD&#125;</span></span><br><span class="line">hideList = [<span class="string">&#x27;AT&#x27;</span>, <span class="string">&#x27;BEZ&#x27;</span>, <span class="string">&#x27;IN&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;VB&#x27;</span>, <span class="string">&#x27;PERIOD&#x27;</span>]</span><br><span class="line"></span><br><span class="line">hideLen = <span class="built_in">len</span>(hideList)  <span class="comment"># 隐序列长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始概率矩阵 隐序列的每个元素的初始概率 &#123;0.2 0.1 0.1 0.2 0.3 0.1&#125;</span></span><br><span class="line">initChanceList = [<span class="number">0.2</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># viterbi矩阵 记录当前概率最大矩阵,行数为隐序列长度，对应隐序列每个词，列数为观测序列长度，对于观测序列每个词</span></span><br><span class="line">viterbiList = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(hideLen)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(observeLen)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># backPoint矩阵 记录得到viterbi当前最大值对应上一列的坐标（以列循环） 大小和viterbi大小一样</span></span><br><span class="line">backPoint = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(hideLen)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(observeLen)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转移矩阵</span></span><br><span class="line">initTranslateList = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">48636</span>, <span class="number">0</span>, <span class="number">19</span>], [<span class="number">1973</span>, <span class="number">0</span>, <span class="number">426</span>, <span class="number">187</span>, <span class="number">0</span>, <span class="number">38</span>], [<span class="number">43322</span>, <span class="number">0</span>, <span class="number">1325</span>, <span class="number">17314</span>, <span class="number">0</span>, <span class="number">185</span>],</span><br><span class="line">                     [<span class="number">1067</span>, <span class="number">3720</span>, <span class="number">42470</span>, <span class="number">11773</span>, <span class="number">614</span>, <span class="number">21392</span>], [<span class="number">6072</span>, <span class="number">42</span>, <span class="number">4758</span>, <span class="number">1476</span>, <span class="number">129</span>, <span class="number">1522</span>],</span><br><span class="line">                     [<span class="number">8016</span>, <span class="number">75</span>, <span class="number">4656</span>, <span class="number">1329</span>, <span class="number">954</span>, <span class="number">0</span>]]</span><br><span class="line">translateList = InitUtil.getTransferMatrix(initTranslateList)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发射矩阵</span></span><br><span class="line">initObserveList = [<span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;move&#x27;</span>, <span class="string">&#x27;on&#x27;</span>, <span class="string">&#x27;president&#x27;</span>, <span class="string">&#x27;progress&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]</span><br><span class="line">initFireMatrix = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">10</span>, <span class="number">43</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">10065</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">36</span>, <span class="number">133</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">5484</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">382</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">108</span>, <span class="number">4</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">69016</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">48809</span>]]</span><br><span class="line">fireList = InitUtil.getEmissionMatrix(initObserveList, initFireMatrix, observeList)</span><br><span class="line"></span><br><span class="line">result = HMMAndViterbi.hmmViterbi(initChanceList, fireList, translateList, hideList)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最大可能序列为&#x27;</span>, end=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">    <span class="built_in">print</span>(i, end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<hr>
<h3 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h3><h4 id="相关知识-3"><a href="#相关知识-3" class="headerlink" title="相关知识"></a>相关知识</h4><p><strong>字符和字符串相关定义（一些概念与后面概念相关）</strong></p>
<p>假定∑是字符的有限集合，它的每一个元素称为字符。<strong>由∑中字符相连而成的有限序列称为∑上的字符串</strong>。特殊的，不包括任何字符的字符串称为<strong>空串，记作ε</strong>。<strong>包括空串在内的∑上字符串的全体记为∑</strong>*</p>
<p> 链接和闭包是字符串操作中的两种基本运算</p>
<p>假定∑是字符的有限集合，x,y是∑上的符号串，则把y的各个符号一次写在x符号串之后得到的符号串称为x与y的<strong>链接</strong>，记作xy。</p>
<p><em>例如</em>：<br>$$<br>∑&#x3D;{a,b,c}, x&#x3D;abc, y&#x3D;cba, 那么：xy&#x3D;abccba<br>$$</p>
<p>设A,B是字符表∑上符号串的集合，则A和B的<strong>乘积</strong>定义为：<br>$$<br>AB&#x3D;{xy|x∈ A, y∈ B}，其中A^0 &#x3D; {ε}。当n&gt;&#x3D;1时，A^n&#x3D;A^{n-1}A&#x3D;AA^{n-1}<br>$$</p>
<p>字符串V的<strong>闭包</strong>定义为：<br>$$<br>V^*&#x3D;V^0 ∪ V^1 ∪ V^2 ∪ …，<br>V^+ &#x3D; V^1 ∪ V^2 ∪ …， V^+ &#x3D; V^* - {ε}<br>$$<br>例如：<br>$$<br>如果V&#x3D;{a,b} ，则：V^*&#x3D;{ε, a, b, aa, ab, bb, ba, aaa, …}，V^+&#x3D;{a, b, aa, ab, bb, ba, aaa, …}<br>$$</p>
<p><strong>形式语言（形式语法和自动机）</strong></p>
<p>形式语言学（Formal Linguistics）（也称代数语言学），是一门研究语言的科学领域，它主要关注语言的结构、语法、语义、音系和语音等方面的形式性质。形式语言学使用数学符号和形式规则来描述和分析语言，旨在深入理解语言的本质和结构，以及解决语言相关的理论和应用问题。<strong>形式语法理论和自动机理论都属于形式语言理论的一部分。</strong>形式语言理论是自然语言描述和分析的基础（目的是试图用精确的数学模型（形式语言）来刻划自然语言），自动机理论在自然语言的词法分析、拼写检查、短语识别等很多方面都有广泛用途。</p>
<p><strong>描述语言的三种途径</strong></p>
<ul>
<li><p>枚举法</p>
<p>把语言中的句子穷尽地枚举出来，对于含无限多个句子的语言不合适</p>
</li>
<li><p>文法（语法）描述</p>
<p>给出生成语言中所有句子的方法（文法），而且只生成合格的句子，形式文法是一种语言的文法是一种格式，说明什么句子在该语言中是合法的，并指明把词组合成短语和子句的规则。</p>
</li>
<li><p>自动机</p>
<p>对输入的语符序列进行检验，区别哪些是语言中的句子，哪些不是语言中的句子</p>
</li>
</ul>
<p><strong>文法</strong>用来<strong>生成</strong>语言的句子，属于<a href = "#formal grammar">形式语法</a>理论；<strong>自动机</strong>用来<strong>识别</strong>语言的句子,属于自动机理论</p>
<p><strong>形式语法</strong>	<a name = "formal grammar"></a></p>
<ul>
<li><strong>形式语法特点</strong></li>
</ul>
<p>高度形式化和抽象化，是一套演绎系统。（从S出发，依靠有限数量的规则，在有限数量的词汇<br>的基础上，可以产生出无限数量的丰富多彩的句子或终端符序列。）</p>
<ul>
<li><p><strong>形式语法的类型（四种文法之间的关系是逐级包含关系，0型包含1型，1型包含2型，2型包含3型）</strong></p>
<ul>
<li><p><strong>3型文法–正则文法</strong></p>
<p>特点：与2型文法相比，多出的限制是规则右侧最多只能有一个非终端语符紧跟在终端语符的后面<br>$$<br>形式语法G&#x3D;&lt;V_N,V_T,P,S&gt;<br>\ S:表示起始符, S∈V_N;V_N:非终端语符集;V_T:终端语符集,;P表示重写规则集,V&#x3D;V_N∪V_T.<br>\ \ 如果文法G的规则集P中所有规则满足如下形式,则称该文法G为3型文法,形式如下：<br>\ A →Bx, 其中:A,B∈V_N;\ x ∈ V_T<br>$$</p>
</li>
</ul>
<p>$$<br>例子：<br>\ G2&#x3D;&lt;V_N,V_T,P,S&gt;,其中 V_N&#x3D;{S,A,B,C}, V_T&#x3D;{a,b,c}<br>\ P由下列规则组成：<br>S→ABC;\ A→aA;\ A→a;\ B→Bb;\ B→b<br>$$</p>
<ul>
<li><p><strong>2型文法–上下文无关文法</strong></p>
<p>特点：与1型文法相比，多出的限制是α和β必须是“空”的(因为规则的左边必须是非终结符)，即非终结语符的改写不受它出现的语境制约。<br>$$<br>形式语法G&#x3D;&lt;V_N,V_T,P,S&gt;<br>\ S:表示起始符, S∈V_N;V_N:非终端语符集;V_T:终端语符集,;P表示重写规则集,V&#x3D;V_N∪V_T. \ \<br>如果P每个产生式可以描述为A→α,其中A是非终结符，α是空或多个终结符和非终结符的序列<br>\ \ 字符串中A被改写时，不需要上下文语境，体现<br>了上下文无关的含义(物理意义的理解)<br>$$</p>
</li>
</ul>
<p>$$<br>例子:<br>\ G1&#x3D;&lt;V_N,V_T,P,S&gt;<br>\ 其中 V_N&#x3D;{S,A,B,C}, V_T&#x3D;{a,b,c}<br>\ P由下列规则组成：S→ABC;\ A→aA;\ A→a;\ B→Bb;\ B→b<br>$$</p>
<ul>
<li><p><strong>1型文法–上下文相关文法</strong></p>
<p>特点：与0型文法相比，每条规则箭头的左侧只能有一个非终端语符被改写，而且它的改写与上下文有关.<br>$$<br>形式语法G&#x3D;&lt;V_N,V_T,P,S&gt;<br>\ S:表示起始符, S∈V_N;V_N:非终端语符集;V_T:终端语符集,;P表示重写规则集,V&#x3D;V_N∪V_T. \ \<br>如果文法中的所有规则满足如下形式,则称该文法G为1型文法，形式如下： \<br>αAβ →αγβ，其中:<br>A ∈V_N;\ α,β ∈ V^*(即V中零个或多个符号序列);\ 且γ至少包含一个字符<br> \ \ 字符串中A被改写时，需要上文语境α和下文语境β，体现了上下文相关的含义(物理意义的理解)<br>$$</p>
</li>
</ul>
<p>$$<br>例子:<br>\ G1&#x3D;&lt;V_N,V_T,P,S&gt;<br>\ 其中 V_N&#x3D;{S,A,B,C}, V_T&#x3D;{a,b,c}<br>\ P由下列规则组成：<br>S→ABC;\ A→a A | a;\ B→b B|b;\ BC→Bcc<br>\ 该文法所识别的语言为：<br>L(G)&#x3D;{a^nb^mc^2}, n&gt;&#x3D;1, m&gt;&#x3D;1<br>$$</p>
<ul>
<li><p><strong>0型文法–无约束文法</strong></p>
<p>特点：规则部分不加任何限制，可以生成任意句子<br>$$<br>形式语法G&#x3D;&lt;V_N,V_T,P,S&gt; \<br>S:表示起始符, S∈V_N;V_N:非终端语符集;V_T:终端语符集,;P表示重写规则集,V&#x3D;V_N∪V_T. \ \<br>如果文法中的所有规则满足如下形式,则称该文法G为0型文法，形式如下： \<br>α → β，其中: \<br>α ∈ V^+(V的正闭包，即V中一个或多个符号序列),\β∈V^*(V的自反闭包,即V中零个或多个符号序列)<br>$$</p>
</li>
</ul>
</li>
</ul>
<p>$$<br>例子(该文法将产生所有非负整数)： \<br>G&#x3D;&lt;V_N,V_T,P,S&gt;，其中 V_N&#x3D;{S,D}, V_T&#x3D;{0,1,2,3,…,9} \<br>P&#x3D;{S→D|SD;\ D→0|1|2|3|4|5|6|7|8|9}<br> \ 解析：S→D; S→SD→DD; S→SD→SDD→DDD…<br>$$</p>
<p><strong>总结</strong><br>从描述能力上说，上下文无关语法不足以描述自然语言，自然语言中上下文相关的情况非常常见； 从计算复杂度来说，上下文无关语法的复杂度是多项式的，其复杂度可以忍受。为弥补上下文无关语法描述能力的不足，需要加上一些其他手段扩充其描述能力。<strong>（这里主要涉及2型文法）</strong>3型文法生成句子是严格顺着一个方向扩展。</p>
<h4 id="句法分析相关概念"><a href="#句法分析相关概念" class="headerlink" title="句法分析相关概念"></a>句法分析相关概念</h4><p>**句法分析(syntatic parsing)**：自然语言处理中的关键技术之一，其基本任务是确定句子的句法结构或句子中词汇之间的依存关系。 </p>
<p><strong>句法分析器（Syntactic Parser）</strong>：是自然语言处理（NLP）中的一个关键组件，用于分析文本的句法结构，即文本中单词和短语之间的语法关系。句法分析器的主要任务是确定文本中的句子是如何构建的，包括词法分析、短语结构分析和句法依存分析。</p>
<p><strong>句法分析分类</strong></p>
<ul>
<li><p>句法结构分析(syntatic structure parsing)</p>
<ul>
<li>成分结构分析(constituent structure parsing)</li>
<li>短语结构分析(phrase structure parsing)</li>
</ul>
</li>
<li><p>依存关系分析(dependency parsing)</p>
</li>
</ul>
<p><em>不同语法形式对应的句法分析不尽相同：基于短语结构语法的句法分析以及基于依存关系语法的依存句法分析</em></p>
<p>另一种分类</p>
<ul>
<li><p>完全句法分析 或 完全短语结构分析：</p>
<p>获取整个句子的句法结构</p>
<p>Full syntactic parsing ；Full phrase structure parsing；Full parsing</p>
</li>
<li><p>浅层句法分析 (partial parsing)</p>
<p>获得局部成分(如名词短语)的句法分析</p>
</li>
</ul>
<p><strong>依存语法</strong>：又称从属关系语法，便于计算机对自然语言进行处理</p>
<p>所谓依存是指词与词之间支配与被支配的关系,是一种有方向的不对等关系.处于支配地位的成分成为支配者<br>(government,head),处于被支配地位的成分成为从属者(modifier,dependency)。在依存结构图中，依存语法的支配者和从属者被描述为head和dependency，支配和被支配的关系用带有方向的边来表示。</p>
<p><strong>基于依存语法的依存句法分析</strong></p>
<p>分析图片来源：<a target="_blank" rel="noopener" href="https://www.ltp-cloud.com/">语言云（语言技术平台云 LTP-Cloud）</a></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311072344927.png" alt="image-20231107230440197"></p>
<p><strong>基于短语结构语法的句法分析</strong></p>
<p>短语结构语法，如基于上下文无关语法的短语结构树句法分析。（主要涉及上下文无关语法）</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311072344072.png" alt="image-20231107230646255"></p>
<p><strong>基本策略</strong></p>
<p>一个句法分析可以表述为一个搜索过程，搜索空间是语法规则，搜索过程是检查各种语法规则所有可能的组合方式，目的是最终找到一种组合，其中的语法规则能够生成一棵用来表示句子结构的句法树。</p>
<p>句法分析常用策略有：</p>
<ul>
<li>自顶向下分析法（这里讲解）；</li>
<li>自底向上分析法；</li>
<li>左角分析法；</li>
<li>其他策略。</li>
</ul>
<p>句法分析的过程也可以理解为句法树的构造过程；所谓自顶向下分析法也就是先构造句法树的根结点，再逐步向下扩展，直到叶结点；所谓自底向上分析法也就是先构造句法树的叶结点，再逐步向上合并，直到根结点。</p>
<p><strong>自顶向下算法描述：</strong></p>
<p>1.初始当前状态为((s) 1)记为C，候选状态为空；<br>2.当算法未失败且算法未成功，则重复：<br>    (1)若C是空字符列且词位置到了句尾，则算法成功，返回。<br>    (2)若当前状态和候选状态都为空，且词未知未到句尾，则算法失败，返回。否则，产生新状态：<br>        • 若C中字符列的第一个字符是句子中下一个词的词类，则从字符列中移去第一个字符，并修改词位置，修改后的状态为当前状态，记为C，转(2)。<br>        • 若C中字符列的第一个字符是非终止符β，用语法中能重写β的每个规则产生新状态，产生的第一个状态为当<br>前状态（记为C)，产生的其它状态加入到候选状态的栈顶，转（2）.<br>        • 否则，回溯，从候选状态中取出栈顶作为当前状态。</p>
<p><strong>自顶向下分析算法示例：</strong></p>
<table>
<thead>
<tr>
<th>初始状态</th>
<th>候选状态</th>
<th>comment备注</th>
</tr>
</thead>
<tbody><tr>
<td>((S)1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>((NP VP)1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>((ART N VP)1)</td>
<td>((ART ADJ N VP)1)</td>
<td>匹配the，修改初始状态为下一行初始状态</td>
</tr>
<tr>
<td>((N VP)2)</td>
<td></td>
<td>匹配old</td>
</tr>
<tr>
<td>((VP)3)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>((V)3)</td>
<td>((V NP)3)</td>
<td>匹配man</td>
</tr>
<tr>
<td>(()4)</td>
<td></td>
<td>为空但是未到词尾，回溯，从候选状态栈弹出一个状态</td>
</tr>
<tr>
<td>((V NP)3)</td>
<td></td>
<td>匹配man</td>
</tr>
<tr>
<td>((NP)4)</td>
<td></td>
<td>匹配失败，回溯</td>
</tr>
<tr>
<td>((ART ADJ N VP)1)</td>
<td></td>
<td>匹配the</td>
</tr>
<tr>
<td>((ADJ N VP)2)</td>
<td></td>
<td>匹配old</td>
</tr>
<tr>
<td>((N VP)3)</td>
<td></td>
<td>匹配man</td>
</tr>
<tr>
<td>((VP)4)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>((V)4)</td>
<td>((V NP)4)</td>
<td>匹配cried</td>
</tr>
<tr>
<td>(()5)</td>
<td></td>
<td>成功</td>
</tr>
</tbody></table>
<h4 id="基于规则的句法分析"><a href="#基于规则的句法分析" class="headerlink" title="基于规则的句法分析"></a>基于规则的句法分析</h4><p>使用手工定义的语法规则和规则匹配算法来分析句子结构。这需要领域专家手动创建规则，因此适用于特定领域或语言。上面的自顶向上就是一种基于规则的句法分析。</p>
<p><strong>缺点：</strong></p>
<p>计算量大，情况复杂，一些情况下回溯可能很多，不太合理</p>
<p>Top-Down Parsing: 从起始符开始搜索派生空间<br>Bottom-up Parsing:从终止符开始，反向搜索派生空间<br>• 属于全搜索，时间复杂度高，不够灵活</p>
<h4 id="基于统计的句法分析"><a href="#基于统计的句法分析" class="headerlink" title="基于统计的句法分析"></a>基于统计的句法分析</h4><p>用统计方法和机器学习算法从大量已标注的语料库中学习语法结构。常见的方法包括基于PCFG（Probabilistic Context-Free Grammar）的方法和基于依存关系的方法。</p>
<p><strong>分析：</strong></p>
<p>自顶向下算法最坏情况下需要回溯多次，算法优化方面依然是使用基于使用动态规划思想的句法分析算法，这类算法有CKY、Earley Parser、Chart Parsers，这里主要介绍的是CKY算法。</p>
<ul>
<li><p>CKY (Cocke-Kasami-Younger) </p>
<p> 基于自底向上的句法分析算法CKY，该算法需要首先规范化语法。</p>
</li>
<li><p>Earley Parser</p>
<p>基于自顶向下的句法分析算法Earley算法，该算法部需要规范化语法。</p>
</li>
<li><p>Chart Parsers</p>
</li>
</ul>
<p>  线图算法，它在图表中完整保留短语，并且可以组合自顶向下和自底向上搜索策略。</p>
<h5 id="CKY算法"><a href="#CKY算法" class="headerlink" title="CKY算法"></a>CKY算法</h5><p><strong>相关内容：</strong></p>
<ul>
<li><p>上下文无关文法(CFG)</p>
</li>
<li><p>乔姆斯基范式(Chomsky normal form,CNF)</p>
<p>在该范式中，产生式只有2个非终端语符或者1个终端语符。</p>
</li>
</ul>
<p><strong>思想：</strong></p>
<p>为了方便实现自底向上的运算，CKY算法首先需要将CFG文法转换为乔布斯基范式</p>
<p>详细思路可以通过下面博客查看，下面记录一下老师上课讲的<strong>乔布斯基范式CNF的转换</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39378221/article/details/103788893?ops_request_misc=%7B%22request_id%22:%22170058410216800226552953%22,%22scm%22:%2220140713.130102334..%22%7D&request_id=170058410216800226552953&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-103788893-null-null.142%5Ev96%5Epc_search_result_base9&utm_term=cyk&spm=1018.2226.3001.4187">句法分析——CYK分析算法_cyk算法-CSDN博客</a></p>
<p>$$<br>给定一个句子s &#x3D; w_1,w_2,…,w_3,和一个上下文无关文法PCFG,G&#x3D;(T,S,R,P)<br>\ 定义一个跨越单词i到j的概率最大的语法成分π:π(i,j,X)(i,j∈1…N,X∈N),<br>\ 目标是找到一个属于π[1,n,s]中所有树中概率最大的那棵。<br>\ \ CYK算法用于PCFG下的句法分析:<br>\ ·基本定义:for\ all\ i&#x3D;1,…,n,X∈N<br>\ π(i,i,X)&#x3D;q(X→w_i) (if\ X → w_i 没有出现在语法中，则定义q(X → w_i)&#x3D;0)<br>\ ·递归定义:for\ all\ i&#x3D;1,…,n, j&#x3D;(i+1),…,n, X ∈N<br>\ π(i,j,X)&#x3D;max(q(X→YZ)×π(i,k,Y)×π(k+1,j,Z)) (i≤k≤j−1)<br>$$</p>
<p><strong>乔布斯基范式CNF的转换：</strong></p>
<ol>
<li>递归删除空</li>
<li>递归删除一元</li>
<li>对于规则中右边有超过2个非终结符时，则引入新的非终结符来处理</li>
</ol>
<p>（注意递归的概念）</p>
<ol>
<li><p>将NP以空替换其他规则（递归删除空）</p>
<p>注意一次只能改写一个</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220831046.png" alt="image-20231119164857317"></p>
</li>
</ol>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220831095.png" alt="image-20231119164916995"></p>
<p>紫色部分表示用<code>NP-&gt;empty</code>将原来的<code>S-&gt;NP VP</code>替换成了<code>S-&gt;VP</code></p>
<ol start="2">
<li><p>递归处理一元</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220831281.png" alt="image-20231119223512972"></p>
<p>像这里第一个一元就是<code>S-&gt;VP</code>，第一个要处理的就是这个，可以得到右边紫色的结果，最后所有的结果如下</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220831640.png" alt="image-20231119223717804"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220831015.png" alt="image-20231119223737957"></p>
</li>
</ol>
<p>接着就是处理第二个一元<code>S-&gt;V</code>，之后同理一直处理一元</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220832161.png" alt="image-20231119223939110"></p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220832596.png" alt="image-20231119223950260"></p>
<p>处理完的结果如下：</p>
<p><img src="C:\Users\GTR\AppData\Roaming\Typora\typora-user-images\image-20231119223958338.png" alt="image-20231119223958338"></p>
<ol start="3">
<li><p>递归处理三元及以上结果</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202311220832975.png" alt="image-20231119224136022"></p>
</li>
</ol>
<p><strong>分析</strong><br>$$<br>时间复杂度：<br>\有 (n(n+1)&#x2F;2) &#x3D; O(n^2) 格子<br>\有 O(n) 个可能的分裂点<br>\总的时间复杂度为 O(n^3)<br>\并且可能存在多个句法树的情况，没有局部最优的概念，下面引进的概率就是解决相关问题的<br>$$</p>
<h5 id="概率CKY统计句法分析算法"><a href="#概率CKY统计句法分析算法" class="headerlink" title="概率CKY统计句法分析算法"></a>概率CKY统计句法分析算法</h5><p><strong>相关概念</strong></p>
<p>上下文无关文法CFG</p>
<p>概率上下文无关文法PCFG</p>
<p><strong>理解</strong></p>
<p>无概率的CFG分析符合语法的句子，答案只有两个：是或不是；基于概率上下文无关文法PCFG，则是分析符合语法的句子的可能性，即为一个概率值。</p>
<h5 id="扩展CKY句法分析算法"><a href="#扩展CKY句法分析算法" class="headerlink" title="扩展CKY句法分析算法"></a>扩展CKY句法分析算法</h5><p>这个其实就是上面的概率CKY统计句法分析算法在书写代码中的变种，这里主要讲这种。</p>
<p>在这种算法书写思路中一元可以整合进入算法，虽然使得语法有点凌乱，但是并不增加算法的复杂度，空也可以整合进入算法，和一元一样，并不增加算法的复杂度</p>
<p><strong>理解和分析（可以看看其中例题的分析过程）</strong></p>
<p>这份博客的作者应该是广外毕业的，毕竟昵称很直接</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Chase1998/article/details/84504191?ops_request_misc=&request_id=&biz_id=102&utm_term=%E5%9F%BA%E4%BA%8Ecyk+PCFG&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-84504191.142%5Ev96%5Epc_search_result_base9&spm=1018.2226.3001.4187">基于CYK+PCFG的短语结构句法分析-CSDN博客</a></p>
<p><strong>个人代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 核心类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCKY</span>:</span><br><span class="line">    <span class="comment"># tuple_all保存所有出现的语符序列</span></span><br><span class="line">    <span class="comment"># tuple_one保存一元，如其中一个元素为(0.1, &#x27;S&#x27;, &#x27;VP&#x27;)表示&#x27;S-&gt;VP 0.1&#x27;</span></span><br><span class="line">    <span class="comment"># tuple_two保存二元，如其中一个元素为(0.9, &#x27;S&#x27;, (&#x27;NP&#x27;, &#x27;VP&#x27;))表示&#x27;S-&gt;NP VP 0.9&#x27;</span></span><br><span class="line">    <span class="comment"># tuple_over保存终端语符号,如其中一个元素(0.5, &#x27;N&#x27;, &#x27;people&#x27;)表示&#x27;N-&gt;people 0.5&#x27;</span></span><br><span class="line">    <span class="comment"># statement为需要分析的句子</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tuple_one, tuple_two, tuple_over, statement</span>):</span><br><span class="line">        self.tuple_one = tuple_one</span><br><span class="line">        self.tuple_two = tuple_two</span><br><span class="line">        self.tuple_over = tuple_over</span><br><span class="line">        self.statement = statement.split(<span class="string">&#x27; &#x27;</span>)  <span class="comment"># 切分字符串得到列表</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理过程，主方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">solve</span>(<span class="params">self</span>):</span><br><span class="line">        len_s = <span class="built_in">len</span>(self.statement)  <span class="comment"># 字符串词数</span></span><br><span class="line">        <span class="comment"># 创建记录矩阵</span></span><br><span class="line">        matrix = [[<span class="literal">None</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(len_s)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(len_s)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 叶子节点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_s):</span><br><span class="line">            list_add = []  <span class="comment"># 保存添加的值</span></span><br><span class="line">            <span class="comment"># index_start保存本次开始坐标，index_end保存本次结束坐标，遍历过的下次不遍历</span></span><br><span class="line">            index_start = <span class="number">0</span></span><br><span class="line">            index_end = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 终端语符</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> self.tuple_over:</span><br><span class="line">                <span class="keyword">if</span> j[<span class="number">2</span>] == self.statement[i]:</span><br><span class="line">                    <span class="comment"># 记录以回溯,叶子节点的终端语符记录为None</span></span><br><span class="line">                    temp = <span class="built_in">list</span>(j)</span><br><span class="line">                    temp.append(<span class="literal">None</span>)</span><br><span class="line">                    list_add.append(temp)</span><br><span class="line">                    index_end += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 一元</span></span><br><span class="line">            <span class="keyword">while</span> index_start &lt; index_end:</span><br><span class="line">                last_index_end = index_end  <span class="comment"># 遍历过的下次不遍历，保存上次的结束坐标，待会赋值给开始坐标</span></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> self.tuple_one:</span><br><span class="line">                    <span class="comment"># 修改概率，相乘</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(index_start, index_end):</span><br><span class="line">                        <span class="keyword">if</span> j[<span class="number">2</span>] == list_add[k][<span class="number">1</span>]:</span><br><span class="line">                            temp = <span class="built_in">list</span>(j)</span><br><span class="line">                            temp[<span class="number">0</span>] *= list_add[k][<span class="number">0</span>]  <span class="comment"># 更改概率</span></span><br><span class="line">                            <span class="comment"># 记录以回溯,叶子节点的一元加入的记录为本位置[i,i]</span></span><br><span class="line">                            temp.append([i, i])</span><br><span class="line">                            index_end += <span class="number">1</span></span><br><span class="line">                            list_add.append(temp)</span><br><span class="line">                index_start = last_index_end</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 填入</span></span><br><span class="line">            matrix[i][i] = list_add</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印叶子节点处理结果</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_s):</span><br><span class="line">            <span class="built_in">print</span>(matrix[i][i])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 非叶子节点</span></span><br><span class="line">        step = <span class="number">1</span></span><br><span class="line">        <span class="comment"># t控制循环次数，也就是列数-1</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(len_s - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_s - step):</span><br><span class="line">                <span class="comment"># 根据横纵坐标关系确认当前处理的点 j = i + step</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 保存添加的值</span></span><br><span class="line">                list_add = []</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 切分的下标</span></span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(i, i + step):</span><br><span class="line">                    list1 = matrix[i][k]</span><br><span class="line">                    list2 = matrix[k + <span class="number">1</span>][i + step]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 从二元中看哪个能推导出来</span></span><br><span class="line">                    <span class="keyword">for</span> i1 <span class="keyword">in</span> list1:</span><br><span class="line">                        <span class="keyword">for</span> j1 <span class="keyword">in</span> list2:</span><br><span class="line">                            <span class="keyword">for</span> k1 <span class="keyword">in</span> self.tuple_two:</span><br><span class="line">                                <span class="keyword">if</span> k1[<span class="number">2</span>][<span class="number">0</span>] == i1[<span class="number">1</span>] <span class="keyword">and</span> k1[<span class="number">2</span>][<span class="number">1</span>] == j1[<span class="number">1</span>]:</span><br><span class="line">                                    temp = <span class="built_in">list</span>(k1)</span><br><span class="line">                                    temp[<span class="number">0</span>] *= (i1[<span class="number">0</span>] * j1[<span class="number">0</span>])</span><br><span class="line">                                    <span class="comment"># 记录回溯，二元保存两个分支的来源</span></span><br><span class="line">                                    temp.append([i, k])</span><br><span class="line">                                    temp.append([k + <span class="number">1</span>, i + step])</span><br><span class="line"></span><br><span class="line">                                    <span class="comment"># 下面遍历list_add以保存最大概率的决定值相同的</span></span><br><span class="line">                                    <span class="keyword">if</span> <span class="built_in">len</span>(list_add) == <span class="number">0</span>:</span><br><span class="line">                                        list_add.append(temp)</span><br><span class="line"></span><br><span class="line">                                    <span class="keyword">for</span> t1 <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list_add)):</span><br><span class="line">                                        <span class="comment"># 找到相同的决定项就能break了，保证唯一，走到最后就直接加进去就行</span></span><br><span class="line">                                        <span class="keyword">if</span> list_add[t1][<span class="number">1</span>] == temp[<span class="number">1</span>]:</span><br><span class="line">                                            <span class="keyword">if</span> temp[<span class="number">0</span>] &gt; list_add[t1][<span class="number">0</span>]:</span><br><span class="line">                                                <span class="comment"># 修改以回溯</span></span><br><span class="line">                                                list_add[t1] = temp</span><br><span class="line"></span><br><span class="line">                                            <span class="keyword">break</span></span><br><span class="line">                                        <span class="keyword">if</span> t1 == <span class="built_in">len</span>(list_add) - <span class="number">1</span>:</span><br><span class="line">                                            list_add.append(temp)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 从一元中再寻找是否有决定值一样的且能推导出且概率大的</span></span><br><span class="line">                <span class="keyword">for</span> i1 <span class="keyword">in</span> self.tuple_one:</span><br><span class="line">                    <span class="keyword">for</span> j1 <span class="keyword">in</span> list_add:</span><br><span class="line">                        <span class="keyword">if</span> i1[<span class="number">1</span>] == j1[<span class="number">1</span>]:</span><br><span class="line">                            <span class="comment"># 能够推导的</span></span><br><span class="line">                            <span class="keyword">for</span> k1 <span class="keyword">in</span> list_add:</span><br><span class="line">                                <span class="keyword">if</span> i1[<span class="number">2</span>] == k1[<span class="number">1</span>] <span class="keyword">and</span> i1[<span class="number">0</span>] * k1[<span class="number">0</span>] &gt; j1[<span class="number">0</span>]:</span><br><span class="line">                                    temp = <span class="built_in">list</span>(i1)</span><br><span class="line">                                    temp[<span class="number">0</span>] = i1[<span class="number">0</span>] * k1[<span class="number">0</span>]</span><br><span class="line">                                    <span class="comment"># 记录回溯，一元替换把之前的删除了并把回溯记录为当前节点</span></span><br><span class="line">                                    temp.append([i, i + step])</span><br><span class="line">                                    list_add.append(temp)</span><br><span class="line">                                    list_add.remove(j1)  <span class="comment"># 移除概率小的</span></span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(list_add)</span><br><span class="line">                matrix[i][i + step] = list_add</span><br><span class="line"></span><br><span class="line">            step += <span class="number">1</span>  <span class="comment"># 每次循环step+1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理最后一层找到概率最大放入递归回溯</span></span><br><span class="line">        <span class="built_in">max</span> = <span class="number">0</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        list1 = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> matrix[<span class="number">0</span>][len_s - <span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">if</span> i[<span class="number">0</span>] &gt; <span class="built_in">max</span>:</span><br><span class="line">                <span class="built_in">max</span> = i[<span class="number">0</span>]</span><br><span class="line">                index = matrix[<span class="number">0</span>][len_s - <span class="number">1</span>].index(i)</span><br><span class="line">        list1.append(matrix[<span class="number">0</span>][len_s - <span class="number">1</span>][index])</span><br><span class="line"></span><br><span class="line">        self.backtrack(matrix, <span class="number">0</span>, list1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># list1表示本层的list，顶节点需要先找出概率最大放到list1传入</span></span><br><span class="line">    <span class="comment"># t表示树的第几层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backtrack</span>(<span class="params">self, matrix, t, list1</span>):</span><br><span class="line">        <span class="comment"># print(t)</span></span><br><span class="line">        <span class="comment"># 不是所有都为None就继续，所有为空就结束</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list1)):</span><br><span class="line">            <span class="keyword">if</span> list1[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">len</span>(list1) - <span class="number">1</span> <span class="keyword">and</span> list1[i] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">        <span class="built_in">print</span>()  <span class="comment"># 回车</span></span><br><span class="line">        <span class="comment"># 保存下一层</span></span><br><span class="line">        list_temp = [<span class="literal">None</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** (t + <span class="number">1</span>))]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** t):</span><br><span class="line">            <span class="comment"># 输出并保存下一层的值</span></span><br><span class="line">            <span class="keyword">if</span> list1[i] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="literal">None</span>, end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(list1[i]) == <span class="number">4</span>:</span><br><span class="line">                <span class="keyword">if</span> list1[i][<span class="number">3</span>] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="built_in">print</span>(list1[i][<span class="number">1</span>], end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;(&#x27;</span> + list1[i][<span class="number">2</span>] + <span class="string">&#x27;)&#x27;</span>, end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="built_in">print</span>(list1[i][<span class="number">1</span>], end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">                    list_temp[i * <span class="number">2</span>] = self.getRightList(matrix, list1[i][<span class="number">2</span>][<span class="number">0</span>], list1[i][<span class="number">3</span>])</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(list1[i]) == <span class="number">5</span>:</span><br><span class="line">                <span class="built_in">print</span>(list1[i][<span class="number">1</span>], end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">                list_temp[i * <span class="number">2</span>] = self.getRightList(matrix, list1[i][<span class="number">2</span>][<span class="number">0</span>], list1[i][<span class="number">3</span>])</span><br><span class="line">                list_temp[i * <span class="number">2</span> + <span class="number">1</span>] = self.getRightList(matrix, list1[i][<span class="number">2</span>][<span class="number">1</span>], list1[i][<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        self.backtrack(matrix, t + <span class="number">1</span>, list_temp)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过坐标寻找matrix的块中正确的值</span></span><br><span class="line">    <span class="comment"># list1存储坐标</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getRightList</span>(<span class="params">self, matrix, target, list1</span>):</span><br><span class="line">        list_all = matrix[list1[<span class="number">0</span>]][list1[<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> list_all:</span><br><span class="line">            <span class="keyword">if</span> i[<span class="number">1</span>] == target:</span><br><span class="line">                <span class="keyword">return</span> i</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试用例</span></span><br><span class="line"><span class="keyword">from</span> Homewrok3.PCKY <span class="keyword">import</span> PCKY</span><br><span class="line"></span><br><span class="line">tuple_one = (</span><br><span class="line">    (<span class="number">0.1</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>),</span><br><span class="line">    (<span class="number">0.1</span>, <span class="string">&#x27;VP&#x27;</span>, <span class="string">&#x27;V&#x27;</span>),</span><br><span class="line">    (<span class="number">0.7</span>, <span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;N&#x27;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tuple_two = (</span><br><span class="line">    (<span class="number">0.9</span>, <span class="string">&#x27;S&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>)),</span><br><span class="line">    (<span class="number">0.5</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>)),</span><br><span class="line">    (<span class="number">0.3</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;@VP_V&#x27;</span>)),</span><br><span class="line">    (<span class="number">0.1</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;PP&#x27;</span>)),</span><br><span class="line">    (<span class="number">1.0</span>, <span class="string">&#x27;@VP_V&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;PP&#x27;</span>)),</span><br><span class="line">    (<span class="number">0.1</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>)),</span><br><span class="line">    (<span class="number">0.2</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;PP&#x27;</span>)),</span><br><span class="line">    (<span class="number">1.0</span>, <span class="string">&#x27;PP&#x27;</span>, (<span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tuple_over = (</span><br><span class="line">    (<span class="number">0.5</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;people&#x27;</span>),</span><br><span class="line">    (<span class="number">0.2</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>),</span><br><span class="line">    (<span class="number">0.2</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;tanks&#x27;</span>),</span><br><span class="line">    (<span class="number">0.1</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;rods&#x27;</span>),</span><br><span class="line">    (<span class="number">0.1</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;people&#x27;</span>),</span><br><span class="line">    (<span class="number">0.6</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>),</span><br><span class="line">    (<span class="number">0.3</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;tanks&#x27;</span>),</span><br><span class="line">    (<span class="number">1.0</span>, <span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;with&#x27;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">pcky = PCKY(tuple_one, tuple_two, tuple_over, <span class="string">&#x27;fish people fish tanks&#x27;</span>)</span><br><span class="line">pcky.solve()</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 允许结果如图</span></span><br><span class="line">[[<span class="number">0.2</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.6</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.06</span>, <span class="string">&#x27;VP&#x27;</span>, <span class="string">&#x27;V&#x27;</span>, [<span class="number">0</span>, <span class="number">0</span>]], [<span class="number">0.13999999999999999</span>, <span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;N&#x27;</span>, [<span class="number">0</span>, <span class="number">0</span>]], [<span class="number">0.006</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>, [<span class="number">0</span>, <span class="number">0</span>]]]</span><br><span class="line">[[<span class="number">0.5</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;people&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.1</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;people&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.010000000000000002</span>, <span class="string">&#x27;VP&#x27;</span>, <span class="string">&#x27;V&#x27;</span>, [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0.35</span>, <span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;N&#x27;</span>, [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0.0010000000000000002</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>, [<span class="number">1</span>, <span class="number">1</span>]]]</span><br><span class="line">[[<span class="number">0.2</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.6</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.06</span>, <span class="string">&#x27;VP&#x27;</span>, <span class="string">&#x27;V&#x27;</span>, [<span class="number">2</span>, <span class="number">2</span>]], [<span class="number">0.13999999999999999</span>, <span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;N&#x27;</span>, [<span class="number">2</span>, <span class="number">2</span>]], [<span class="number">0.006</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>, [<span class="number">2</span>, <span class="number">2</span>]]]</span><br><span class="line">[[<span class="number">0.2</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;tanks&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.3</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;tanks&#x27;</span>, <span class="literal">None</span>], [<span class="number">0.03</span>, <span class="string">&#x27;VP&#x27;</span>, <span class="string">&#x27;V&#x27;</span>, [<span class="number">3</span>, <span class="number">3</span>]], [<span class="number">0.13999999999999999</span>, <span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;N&#x27;</span>, [<span class="number">3</span>, <span class="number">3</span>]], [<span class="number">0.003</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>, [<span class="number">3</span>, <span class="number">3</span>]]]</span><br><span class="line">[[<span class="number">0.105</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0.0049</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0.0105</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>, [<span class="number">0</span>, <span class="number">1</span>]]]</span><br><span class="line">[[<span class="number">0.006999999999999999</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]], [<span class="number">0.0189</span>, <span class="string">&#x27;S&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>), [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]], [<span class="number">0.0049</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]]]</span><br><span class="line">[[<span class="number">0.041999999999999996</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]], [<span class="number">0.0019599999999999995</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]], [<span class="number">0.0042</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>, [<span class="number">2</span>, <span class="number">3</span>]]]</span><br><span class="line">[[<span class="number">0.00147</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>]], [<span class="number">0.0008819999999999998</span>, <span class="string">&#x27;S&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>]], [<span class="number">6.859999999999999e-05</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>]]]</span><br><span class="line">[[<span class="number">9.799999999999998e-05</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]], [<span class="number">0.013229999999999999</span>, <span class="string">&#x27;S&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>), [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]], [<span class="number">6.859999999999999e-05</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]]]</span><br><span class="line">[[<span class="number">2.0579999999999996e-05</span>, <span class="string">&#x27;VP&#x27;</span>, (<span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">3</span>]], [<span class="number">0.00018521999999999996</span>, <span class="string">&#x27;S&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;VP&#x27;</span>), [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]], [<span class="number">9.603999999999997e-07</span>, <span class="string">&#x27;NP&#x27;</span>, (<span class="string">&#x27;NP&#x27;</span>, <span class="string">&#x27;NP&#x27;</span>), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">3</span>]]]</span><br><span class="line"></span><br><span class="line">S	</span><br><span class="line">NP	VP	</span><br><span class="line">NP	NP	V(fish)	NP	</span><br><span class="line">N(fish)	<span class="literal">None</span>	N(people)	<span class="literal">None</span>	<span class="literal">None</span>	<span class="literal">None</span>	N(tanks)	<span class="literal">None</span>	</span><br></pre></td></tr></table></figure>

<p><strong>这里最终输出的句法树可能有点难理解，这里解释一下，就是层次遍历的去看，第一层节点为S，第二层为NP VP，第三层为NP NP V NP，以此类推，最中每层都跟上层形成二叉树的连接即可，None为空，也就是不存在，后面带括号的，如V(fish)表示V后直接再接一个fish即可</strong></p>
<p><strong>总结</strong></p>
<p>CKY算法在PCFG下的改进算法(PCKY)，其优点在于：</p>
<ul>
<li><p>存储局部最优语法成分；</p>
</li>
<li><p>搜索空间减少；</p>
</li>
<li><p>获得结果更为准确的句法树。</p>
</li>
</ul>
<p>缺点：依赖于上下文无关文法PCFG，而大规模这样的语法实际是比较难以人工标注的。</p>
<p><strong>最后，基于同一个语句生成的不同句法分析树哪个更符合语言需求就是后面的语义分析</strong></p>
<h3 id="语义分析"><a href="#语义分析" class="headerlink" title="语义分析"></a>语义分析</h3><h2 id="应用部分"><a href="#应用部分" class="headerlink" title="应用部分"></a>应用部分</h2><h3 id="2023自然语言处理大作业"><a href="#2023自然语言处理大作业" class="headerlink" title="2023自然语言处理大作业"></a>2023自然语言处理大作业</h3><h4 id="本文算法"><a href="#本文算法" class="headerlink" title="本文算法"></a>本文算法</h4><h5 id="算法概述"><a href="#算法概述" class="headerlink" title="算法概述"></a>算法概述</h5><p><strong>中文纠错算法</strong></p>
<p>本系统中使用的中文文本纠错算法会根据输入词语返回词频最高的正确词语，也就是概率最大的可经过编辑操作获取到词语。</p>
<p>本算法结合了编辑距离算法思想，也就是一个拼写错误的字符串可以通过插入、删除、替换、交换转换成另一个可能为拼写正确的字符串；并且定义了一个规则，两个词语的拼音完全一样则优先级最高；两个词语第一个字的拼音完全一样则优先级次之，其余则优先级最低，再根据优先级高低去寻找词典中存在且词频最高的单词返回，这个单词就是返回的拼写正确的词语。</p>
<p><strong>倒排索引搜索</strong></p>
<p>本系统使用的倒排索引搜索算法主要是构建一个按照TF-IDF进行打分的倒排索引文件，而后对于每个搜索的词语在倒排索引文件中进行搜索，找到相关内容出现的page以及按照打分进行排序。</p>
<p>本算法首先会在对内容进行分词后统计词频生成倒排索引文件，而后会对每个词语索引进行TF-IDF打分，生成最终倒排索引文件。</p>
<h4 id="算法各模块描述"><a href="#算法各模块描述" class="headerlink" title="算法各模块描述"></a>算法各模块描述</h4><h5 id="中文纠错算法"><a href="#中文纠错算法" class="headerlink" title="中文纠错算法"></a>中文纠错算法</h5><p>​	中文纠错算法本质就是拼写检查，其中最重要的思想就是莱文斯坦距离，又称Levenshtein距离，是编辑距离的一种。指两个字串之间，由一个转成另一个所需的最少编辑操作次数。允许的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。莱文斯坦距离以俄国科学家Vladimir levenshtein命名，他于1965年发明了这个算法。<br>$$<br>在数学上，两个字符串a,b的莱文斯坦距离记作lev_{a,b}(|a|,|b|)<br>$$</p>
<p>$$<br>lev_{a,b}(i,j)&#x3D;\begin{cases}<br>    \quad \quad \quad max(i,j)\quad \quad \quad \quad \quad \quad if min(i,j)&#x3D;0,\</p>
<pre><code>min
\begin&#123;cases&#125;
lev_&#123;a,b&#125;(i-1,j)+1\\
lev_&#123;a,b&#125;(i,j-1)+1\\
lev_&#123;a,b&#125;(i-1,j-1)+1_&#123;(a_i≠b_j)&#125;
\end&#123;cases&#125;
</code></pre>
<p>   otherwise</p>
<p>  \end{cases}<br>$$</p>
<p>$$<br>这里，|a|和|b|分别表示字符串a和b的长度,1_{(a_i≠b_j)}是当a_i≠b_j时值为1，否则值为0的示性函数。<br>\这样,lev_{a,b}(i,j)是a的前i个字符和b的前j个字符之间的距离。<br>$$</p>
<p>​	</p>
<p><strong>下面是本算法的具体流程：</strong></p>
<p>①第一步：</p>
<p>首先需要读取数据集，第一个读取的数据集是词频词典phrase_freq，该词典中包含了许多的词语以及搜索的频次；第二个读取的数据集是中文字典cn_words_dict，该字典包含所有的中文汉字。</p>
<p>②第二步：</p>
<p>对于需要纠正的单词按照下标按照下标切分成为前后两块，L和R，其实就是分治思想，根据不同长度的词语会有许多组合，保存在splits列表中；</p>
<p>之后遍历删除R的第一个字，也就是删除其中任意一个字的所有组合保存到deletes列表中；</p>
<p>之后将满足长度的R的两个字进行交换，也就是其中两个字进行交换的所有组合保存到transposes列表中；</p>
<p>之后从字典中取一个字替换R中第一个字，也就是取一个字和其中任意一个字进行替换的所有组合保存到replaces列表中；</p>
<p>之后从字典中取出一个字去插入到L和R之间，也就是往词语中插入一个字的所有组合保存到inserts列表中；</p>
<p>最后通过set(deletes+transposes+replaces+inserts)借助Python的特性完成去重，得到所有可能的正确组合。</p>
<p>③第三步：</p>
<p>在得到所有可能的正确组合后，遍历并通过Pinyin库取得所有可能正确组合中的组合的拼音，并按照本系统定义的规则，与拼写错误的词语的拼音进行比较，</p>
<p>如果两者拼音相等则把该预测组合加入到一级数组，</p>
<p>剩余的组合中，如果两者的第一个字的拼音相等则把该预测组合加入到二级数组，</p>
<p>剩余的组合则直接全部加入到三级数组中。</p>
<p>④第四步：</p>
<p>从一级数组到三级数组进行遍历，对于每级数组都从词频词典phrase_freq查找是否存在该词语，遍历完成后保存频次最大且在词频词典中存在的词，这个就是一个拼写错误的词语进行纠正后的词语。</p>
<p>⑤第五步：</p>
<p>对于一个句子输入错误进行纠错，则会使用jieba库进行中文分词，得到分词列表，如果有的分词不能直接通过词频词典phrase_freq查询得到，那么就可以认定为拼写错误，就执行第二步到第四步得到正确拼写的词语。最后没有拼写错误的词语以及纠正错误的词语进行拼接就是正确的句子。</p>
<h5 id="倒排索引搜索"><a href="#倒排索引搜索" class="headerlink" title="倒排索引搜索"></a>倒排索引搜索</h5><p><strong>倒排索引</strong></p>
<p>倒排索引(Inverted index) 倒排索引是一种将词项映射到文档的数据结构，这与传统关系型数据库的工作方式不同。可以把倒排索引当做面向词项的而不是面向文档的数据结构。（倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)）</p>
<p>倒排索引：Inverted index，指的是将文档内容中的单词作为索引，将包含该词的文档 ID 作为记录的结构。</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181618301.png"></p>
<p><strong>TF-IDF</strong></p>
<p>TF-IDF（term frequency–inverse document frequency）是一种用于资讯检索与资讯探勘的常用加权术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF实际上是：TF * IDF，TF词频(Term Frequency)，IDF反文档频率(Inverse Document Frequency)。TF表示词条在文档d中出现的频率。IDF的主要思想是：如果包含词条t的文档越少，也就是n越小，IDF越大，则说明词条t具有很好的类别区分能力。如果某一类文档C中包含词条t的文档数为m，而其它类包含t的文档总数为k，显然所有包含t的文档数n&#x3D;m+k，当m大的时候，n也大，按照IDF公式得到的IDF的值会小，就说明该词条t类别区分能力不强。</p>
<p>$$<br>词频tf_{t,d}表示词t出现在文档d中的次数,则\<br>w_{t,d}&#x3D;\begin{cases}<br>1+log_{10}tf_{t,d}\ ,\quad if\ tf_{t,d}&gt;0\<br>\quad\quad\quad 0 \ ,\quad\quad\quad otherwise<br>\end{cases}<br>$$</p>
<p>$$<br>文档频率df_t是指包含词t的文档的总数,\<br>逆文档频率的定义为：\<br>idf_t &#x3D; log_{10}(\frac{N}{df_t})<br>$$</p>
<p>$$<br>那么一个词t的tf-idf权重值为：\<br>tf-idf_{t,d}&#x3D;(1+logtf_{t,d})×log_{10}(\frac{N}{df_t})<br>$$</p>
<p><strong>下面是本算法的具体流程：</strong></p>
<p>①第一步：</p>
<p>首先定义一个cut_word函数，这个函数对文本做一些处理，用空格替换阿拉伯数字、以及各种符号，然后对处理后的文本调用jieba库进行分词，分词后才能进行相关的处理。</p>
<p>②第二步：</p>
<p>首先从数据库读入全部相关的文件，其中每行数据包含标题title、作者author、文章text、翻译translation，并检查翻译字段是否为空，为空则不进行分词，不为空才进行分词，并且对标题、作者和文章都进行分词处理，并用回车区分不同内容并进行拼接，之后再进行第三步生成倒排索引文件（没有进行TF-IDF打分）。</p>
<p>③第三步：</p>
<p>这一步主要就是生成倒排索引的核心步骤之一。</p>
<p>遍历第二步经过处理的列表，经过分词处理的文本进行切割得到所有出现的词语，借助这些词语借助Counter类统计TF词频，并保存在index字典中，如果字典中的键存在这个词语就说明统计过，则可以直接在原本的值后面拼接出现的文本page和在当前page出现的频率，没有就新加键并保存值，倒排索引生成完成，保存在index字典中。</p>
<p>④第四步：</p>
<p>这一步主要就是使用TF&#x2F;IDF打分机制进行每个词语的打分，构建最后的倒排索引。</p>
<p>在原本的倒排索引文件的基础上，遍历每个词语，根据键名可以拿到每个词语，而键对应的值就对应每个词语在某篇文章出现的频次tf，可以根据计算得出权重w&#x3D;1.0 + math.log(tf)，而后可以根据值这个列表的长度得到当前词语出现文章的数量df，而所有文章的数量record_count可以直接获取到，那么idf&#x3D;math.log10(record_count &#x2F; df)，计算完成后保存即可。</p>
<p>到这里为止，TF&#x2F;IDF进行打分的倒排索引文件就完成了，后续索引文件即可，对于每次查询可以根据倒排索引快速找到按照分值排序的所有的相关古诗内容。</p>
<h4 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h4><h5 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h5><p><strong>古诗内容相关数据集</strong></p>
<p>其中最重要的数据集就是文章内容相关的数据集了，这份数据集中包含了每首古诗的标题、作者、古诗内容、古诗翻译、作者生活朝代以及更加详细阅读跳转链接。这份数据集是队内组员书写爬虫获取到的数据，进行相关数据处理得到。</p>
<p>下面是存放在数据库中的数据集部分内容：</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181618862.png" alt="微信图片_20231218114520"></p>
<p>这份数据集是用来构建倒排索引文件的重要数据集，对于其中的古诗标题、作者、文本和翻译我们会使用结巴中文分词库进行分词处理，而后统计所有词语的频次，并记录每个词语在不同文档出现的频次（这里的文档包括古诗标题、作者、文本和翻译）以及文档的编号，而后会借助统计信息完成TF-IDF打分，并记录打分值，完成倒排索引文件的构建。</p>
<p>下面就是最终生成的倒排索引文件的部分内容：</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181618898.png" alt="微信图片_20231218114206"></p>
<p><strong>完成拼写检查中编辑距离处理所需数据集</strong></p>
<p>处理编辑距离是完成拼写检查的重要步骤之一，首先需要中文汉字字典，按照单字进行删除、转换、交换、插入操作错误字符串，得到可能正确字符串，再进行后面的比对。</p>
<p>下面是中文汉字字典的部分（收录了3500个中文汉字）：</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181617709.png" alt="image-20231218115746403"></p>
<p>再得到可能正确字符串后就需要进行比对并且需要一个打分机制，我们的系统自定义了规则进行一个预先的排名，而后再对频次进行比较，这里就需要一个搜索词语频次的数据集，其中记录着可能搜索结果和搜索频次（其中也记录着词性，但这在本系统中并没有运用到）。</p>
<p>下面是词频词典的部分（其中有340000多种搜索的可能以及词频）：</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181617310.png" alt="image-20231218120411391"></p>
<h5 id="中文纠错算法细节"><a href="#中文纠错算法细节" class="headerlink" title="中文纠错算法细节"></a>中文纠错算法细节</h5><p>本系统的作文纠错算法中和核心之一就是编辑距离的处理，下面是对一些重要代码的介绍，对于传入的错误拼写词语，会从中文字典中依次去除所有的字，进行删除、调换、转换、插入的操作生成所有的可能正确拼写词语，依次存放在deletes、transposes、replaces、inserts中，之后借助set的特性进行去重。</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181617848.png" alt="image-20231218120703408"></p>
<p>之后便是对于不同可能正确结果的操作进行一个规则的处理，对于错误拼写词语和可能正确词语的拼音进行对比，两者拼音完全相等就存放在一级列表，只有第一个字的拼音相等就存放在二级列表，其余的存放在三级列表中。</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181617777.png" alt="image-20231218121145419"></p>
<p>之后便从不同级别的列表依次去寻找，在级别高的列表中找到则返回，对于同一级别的列表就会调用下面的find_max方法进行查找，对比查找词频词典中的词语，找到词频最大的返回，就对拼写错误的词语进行了纠错。</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181617060.png" alt="image-20231218121521306"></p>
<p>对于需要纠错的句子就只需要调用结巴中文分词库对其进行分词，根据每个词进行处理，若能直接在词频词典中找到则说明没有拼写错误，若查找不到则对每个词调用上面的方法进行纠错，最后局部纠错完成后将所有词语拼接成句子就是对句子的纠错了。</p>
<p><img src="https://gitee.com/wuleizhenshang/person-typora-programming-pic/raw/master/img/202312181617118.png" alt="image-20231218122158235"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.wuleizhenshang.love">无泪真伤</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.wuleizhenshang.love/2023/11/18/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E9%80%89%E4%BF%AE%E8%AF%BE%EF%BC%89/">https://www.wuleizhenshang.love/2023/11/18/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E9%80%89%E4%BF%AE%E8%AF%BE%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.wuleizhenshang.love" target="_blank">Blog-无泪真伤</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></div><div class="post_share"><div class="social-share" data-image="https://pic.imgdb.cn/item/65586ff1c458853aef149c7e.jpg" data-sites="wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/18/%E7%AE%97%E6%B3%95/" title="算法"><img class="cover" src="https://pic.imgdb.cn/item/65587081c458853aef16f416.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">算法</div></div></a></div><div class="next-post pull-right"><a href="/2023/11/17/GitHub+Hexo+Git/" title="GitHub Pages+Hexo+Git快速搭建个人博客"><img class="cover" src="https://pic.imgdb.cn/item/65597baac458853aef754b7b.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">GitHub Pages+Hexo+Git快速搭建个人博客</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/11/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90/" title="神经网络与深度学习速成"><img class="cover" src="https://pic.imgdb.cn/item/6558706bc458853aef16912a.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-18</div><div class="title">神经网络与深度学习速成</div></div></a></div><div><a href="/2023/11/18/%E7%AE%97%E6%B3%95/" title="算法"><img class="cover" src="https://pic.imgdb.cn/item/65587081c458853aef16f416.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-18</div><div class="title">算法</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://pic.imgdb.cn/item/65582252c458853aeff7c6f5.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">无泪真伤</div><div class="author-info__description">找寻自己所爱！</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wuleizhenshang"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">本人并非什么大佬！写博客纯属个人兴趣，记录一下个人学习经历而已，有错误请见谅！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E9%80%89%E4%BF%AE%E8%AF%BE%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">自然语言处理（选修课）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86"><span class="toc-number">1.1.</span> <span class="toc-text">理论部分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80"><span class="toc-number">1.1.2.</span> <span class="toc-text">数学基础</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">概率论基础</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E8%AE%BA"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">信息论</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.3.</span> <span class="toc-text">语言模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">1.1.4.</span> <span class="toc-text">词法分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">相关知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E8%AF%8D"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">分词</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86-1"><span class="toc-number">1.1.4.2.1.</span> <span class="toc-text">相关知识</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.4.2.2.</span> <span class="toc-text">基于规则的中文分词方法</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%AD%A3%E5%90%91%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%B3%95"><span class="toc-number">1.1.4.2.2.1.</span> <span class="toc-text">正向最大匹配法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%B3%95"><span class="toc-number">1.1.4.2.2.2.</span> <span class="toc-text">反向最大匹配法</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.4.2.3.</span> <span class="toc-text">基于统计的中文分词方法</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E6%9C%80%E5%A4%A7%E5%88%86%E8%AF%8D%E6%B3%95%EF%BC%88n%E5%85%83%E8%AF%AD%E6%B3%95%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">1.1.4.2.3.1.</span> <span class="toc-text">概率最大分词法（n元语法模型）</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B3%E6%BB%91"><span class="toc-number">1.1.4.2.3.2.</span> <span class="toc-text">数据平滑</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.4.2.4.</span> <span class="toc-text">基于神经网络的中文分词方法</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">词性标注</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86-2"><span class="toc-number">1.1.4.3.1.</span> <span class="toc-text">相关知识</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.4.3.2.</span> <span class="toc-text">词性标注相关概念</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8"><span class="toc-number">1.1.4.3.3.</span> <span class="toc-text">基于规则的词性标注</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8"><span class="toc-number">1.1.4.3.4.</span> <span class="toc-text">基于统计的词性标注</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.4.3.4.1.</span> <span class="toc-text">前向算法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#HMM-Viterbi"><span class="toc-number">1.1.4.3.4.2.</span> <span class="toc-text">HMM+Viterbi</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">1.1.5.</span> <span class="toc-text">句法分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86-3"><span class="toc-number">1.1.5.1.</span> <span class="toc-text">相关知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.5.2.</span> <span class="toc-text">句法分析相关概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">1.1.5.3.</span> <span class="toc-text">基于规则的句法分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">1.1.5.4.</span> <span class="toc-text">基于统计的句法分析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#CKY%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.5.4.1.</span> <span class="toc-text">CKY算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E7%8E%87CKY%E7%BB%9F%E8%AE%A1%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.5.4.2.</span> <span class="toc-text">概率CKY统计句法分析算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%A9%E5%B1%95CKY%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.5.4.3.</span> <span class="toc-text">扩展CKY句法分析算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90"><span class="toc-number">1.1.6.</span> <span class="toc-text">语义分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E9%83%A8%E5%88%86"><span class="toc-number">1.2.</span> <span class="toc-text">应用部分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2023%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%A4%A7%E4%BD%9C%E4%B8%9A"><span class="toc-number">1.2.1.</span> <span class="toc-text">2023自然语言处理大作业</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AC%E6%96%87%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">本文算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="toc-number">1.2.1.1.1.</span> <span class="toc-text">算法概述</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%90%84%E6%A8%A1%E5%9D%97%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">算法各模块描述</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%AD%E6%96%87%E7%BA%A0%E9%94%99%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.1.2.1.</span> <span class="toc-text">中文纠错算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%90%9C%E7%B4%A2"><span class="toc-number">1.2.1.2.2.</span> <span class="toc-text">倒排索引搜索</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E7%BB%86%E8%8A%82"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">算法细节</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.2.1.3.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%AD%E6%96%87%E7%BA%A0%E9%94%99%E7%AE%97%E6%B3%95%E7%BB%86%E8%8A%82"><span class="toc-number">1.2.1.3.2.</span> <span class="toc-text">中文纠错算法细节</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/11/28/%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E9%87%91%E5%85%B8/" title="程序员面试金典（Java代码）"><img src="https://pic.imgdb.cn/item/67487ddcd0e0a243d4da7860.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="程序员面试金典（Java代码）"/></a><div class="content"><a class="title" href="/2024/11/28/%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E9%87%91%E5%85%B8/" title="程序员面试金典（Java代码）">程序员面试金典（Java代码）</a><time datetime="2024-11-28T14:54:00.000Z" title="发表于 2024-11-28 22:54:00">2024-11-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/18/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F+7%E7%A7%8D%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" title="7大设计原则+23种设计模式（Java代码版本）"><img src="https://pic.imgdb.cn/item/673b421bd29ded1a8cbbff29.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="7大设计原则+23种设计模式（Java代码版本）"/></a><div class="content"><a class="title" href="/2024/11/18/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F+7%E7%A7%8D%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" title="7大设计原则+23种设计模式（Java代码版本）">7大设计原则+23种设计模式（Java代码版本）</a><time datetime="2024-11-18T07:54:00.000Z" title="发表于 2024-11-18 15:54:00">2024-11-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/16/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" title="代码随想录学习记录"><img src="https://s2.loli.net/2024/09/16/rdv2wuJ17ghb3Qj.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="代码随想录学习记录"/></a><div class="content"><a class="title" href="/2024/09/16/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" title="代码随想录学习记录">代码随想录学习记录</a><time datetime="2024-09-16T07:54:00.000Z" title="发表于 2024-09-16 15:54:00">2024-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/16/Leecode%E5%8A%9B%E6%89%A3%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%85%B8150%E9%A2%98/" title="Leecode面试经典150题"><img src="https://s2.loli.net/2024/09/16/JTzk8CZGW7vjXor.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Leecode面试经典150题"/></a><div class="content"><a class="title" href="/2024/09/16/Leecode%E5%8A%9B%E6%89%A3%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%85%B8150%E9%A2%98/" title="Leecode面试经典150题">Leecode面试经典150题</a><time datetime="2024-09-16T07:17:00.000Z" title="发表于 2024-09-16 15:17:00">2024-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/16/%E5%89%91%E6%8C%87offer%E4%B8%AA%E4%BA%BA%E7%AE%97%E6%B3%95%E5%87%86%E5%A4%87/" title="剑指offer个人算法准备"><img src="https://s2.loli.net/2024/09/16/dOZFEfXMl4j2VAs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="剑指offer个人算法准备"/></a><div class="content"><a class="title" href="/2024/09/16/%E5%89%91%E6%8C%87offer%E4%B8%AA%E4%BA%BA%E7%AE%97%E6%B3%95%E5%87%86%E5%A4%87/" title="剑指offer个人算法准备">剑指offer个人算法准备</a><time datetime="2024-09-16T07:17:00.000Z" title="发表于 2024-09-16 15:17:00">2024-09-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By 无泪真伤</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to my blog! --by Wuleizhenshang</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false#  open shake (抖動特效);
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>